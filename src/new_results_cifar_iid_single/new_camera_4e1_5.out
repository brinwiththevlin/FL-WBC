nohup: ignoring input
  0%|          | 0/100 [00:00<?, ?it/s]/home/js905/code/FL-WBC/src/update.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(image), torch.tensor(label)
/home/js905/anaconda2/envs/pytorch0.4/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/home/js905/code/FL-WBC/src/update.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(image), torch.tensor(label_mal), torch.tensor(label)
  1%|          | 1/100 [00:19<32:25, 19.65s/it]  2%|▏         | 2/100 [00:39<32:03, 19.63s/it]  3%|▎         | 3/100 [00:58<31:33, 19.52s/it]  4%|▍         | 4/100 [01:17<31:02, 19.40s/it]  5%|▌         | 5/100 [01:35<30:10, 19.06s/it]  6%|▌         | 6/100 [01:54<29:33, 18.87s/it]  7%|▋         | 7/100 [02:13<29:18, 18.91s/it]  8%|▊         | 8/100 [02:32<29:04, 18.96s/it]  9%|▉         | 9/100 [02:51<28:45, 18.96s/it] 10%|█         | 10/100 [03:10<28:26, 18.96s/it]
Experimental details:
    Model     : cnn
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 100

    Federated parameters:
    IID
    Fraction of users  : 0.1
    Local Batch size   : 10
    Local Epochs       : 10

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
[3545]
malcious dataset true labels: [4], malicious labels: [8]

 | Global Training Round : 1 |

user 21, loss 2.2873933643102644, acc 0.14
user 75, loss 2.291380544900894, acc 0.14
user 41, loss 2.29081124663353, acc 0.1
user 91, loss 2.294007568955421, acc 0.12
user 86, loss 2.2864726936817172, acc 0.1
user 77, loss 2.2825482779741284, acc 0.12
user 54, loss 2.2934468269348143, acc 0.1
user 57, loss 2.294111142158508, acc 0.18
user 1, loss 2.2945988523960112, acc 0.14
user 32, loss 2.272422052025795, acc 0.08
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 1 global rounds:
Training Loss : 2.288719256997109
Global model Benign Test Accuracy: 18.49% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.68 , Outputs: tensor([0.0986])


 | Global Training Round : 2 |

user 5, loss 2.139667703807354, acc 0.22
user 80, loss 2.1381057736277578, acc 0.22
user 1, loss 2.1043076732754713, acc 0.24
user 96, loss 2.1089725542068485, acc 0.22
user 46, loss 2.1382833808660506, acc 0.22
user 95, loss 2.17845747590065, acc 0.28
user 52, loss 2.159568702578545, acc 0.2
user 94, loss 2.1013427659869195, acc 0.2
user 81, loss 2.162410424351692, acc 0.3
user 91, loss 2.172331832051277, acc 0.12
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 2 global rounds:
Training Loss : 2.2145320428311828
Global model Benign Test Accuracy: 25.23% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 292.72 , Outputs: tensor([0.0535])


 | Global Training Round : 3 |

user 88, loss 1.9013830995559693, acc 0.3
user 93, loss 1.9224168381094935, acc 0.24
user 10, loss 1.8862706032395362, acc 0.3
user 25, loss 1.9480948916077612, acc 0.34
user 48, loss 1.9057824662327767, acc 0.22
user 89, loss 1.8605450198054314, acc 0.3
user 47, loss 2.0039552748203273, acc 0.24
user 63, loss 1.9094878530502317, acc 0.22
user 29, loss 1.9408772370219232, acc 0.28
user 26, loss 1.8879730769991874, acc 0.26
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 3 global rounds:
Training Loss : 2.11524757390221
Global model Benign Test Accuracy: 30.98% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 372.99 , Outputs: tensor([0.0240])


 | Global Training Round : 4 |

user 80, loss 1.7271826553344727, acc 0.3
user 49, loss 1.7169127418100831, acc 0.14
user 10, loss 1.6610179422795774, acc 0.28
user 22, loss 1.6981804037094115, acc 0.24
user 59, loss 1.7085040858387948, acc 0.32
user 20, loss 1.7421632301807406, acc 0.32
user 46, loss 1.7178901946544645, acc 0.3
user 31, loss 1.6532640704512596, acc 0.44
user 28, loss 1.693895791321993, acc 0.32
user 42, loss 1.6432467266917228, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 4 global rounds:
Training Loss : 2.0104921264834705
Global model Benign Test Accuracy: 36.13% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 461.61 , Outputs: tensor([0.0099])


 | Global Training Round : 5 |

user 37, loss 1.5107882441580296, acc 0.36
user 18, loss 1.4532233785092832, acc 0.22
user 47, loss 1.561798507273197, acc 0.4
user 41, loss 1.4916713377833368, acc 0.2
user 26, loss 1.4676733183860777, acc 0.28
user 19, loss 1.4134209196269514, acc 0.3
user 69, loss 1.4728633805364368, acc 0.24
user 78, loss 1.4585199052095414, acc 0.32
user 33, loss 1.430891732722521, acc 0.26
user 52, loss 1.514968935698271, acc 0.32
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 5 global rounds:
Training Loss : 1.9039100943848493
Global model Benign Test Accuracy: 38.83% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 648.43 , Outputs: tensor([0.0015])


 | Global Training Round : 6 |

user 92, loss 1.1638778644800185, acc 0.34
user 65, loss 1.1567097425460815, acc 0.32
user 41, loss 1.1432415206730364, acc 0.3
user 45, loss 1.3138195505738257, acc 0.38
user 58, loss 1.2451890756934882, acc 0.22
user 26, loss 1.1718292462825777, acc 0.34
user 21, loss 1.1575016070157287, acc 0.26
user 51, loss 1.1786720079183577, acc 0.36
user 35, loss 1.1875359735637905, acc 0.26
user 25, loss 1.186732239872217, acc 0.34
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 6 global rounds:
Training Loss : 1.7850102257976932
Global model Benign Test Accuracy: 40.51% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 799.95 , Outputs: tensor([0.0003])


 | Global Training Round : 7 |

user 19, loss 0.846463733613491, acc 0.3
user 11, loss 1.0157793929800394, acc 0.4
user 40, loss 1.0120738053508105, acc 0.34
user 41, loss 0.7854948933795096, acc 0.28
user 9, loss 0.9688002950884401, acc 0.36
user 10, loss 0.9447483291476966, acc 0.38
user 63, loss 0.9604843214713037, acc 0.16
user 57, loss 0.9468965613842013, acc 0.32
user 50, loss 0.9670527929812669, acc 0.3
user 75, loss 0.9690482279565185, acc 0.28
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 7 global rounds:
Training Loss : 1.6645350843030695
Global model Benign Test Accuracy: 41.86% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 967.99 , Outputs: tensor([6.2531e-05])


 | Global Training Round : 8 |

user 79, loss 0.7745841914229095, acc 0.36
user 1, loss 0.7966620481014252, acc 0.3
user 67, loss 0.7854628221318125, acc 0.4
user 74, loss 0.7837372190132738, acc 0.26
user 15, loss 0.7953602539096027, acc 0.26
user 68, loss 0.7065167803969234, acc 0.34
user 51, loss 0.6628937011491508, acc 0.24
user 10, loss 0.6472380784759297, acc 0.42
user 95, loss 0.782182813649997, acc 0.22
user 11, loss 0.7097003119997679, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 8 global rounds:
Training Loss : 1.5495224265183205
Global model Benign Test Accuracy: 42.93% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1246.63 , Outputs: tensor([3.8545e-06])


 | Global Training Round : 9 |

user 10, loss 0.5039270688570104, acc 0.44
user 63, loss 0.5890306348889135, acc 0.22
user 13, loss 0.650863875541836, acc 0.32
user 57, loss 0.6122252980736084, acc 0.26
user 52, loss 0.7569863108079881, acc 0.36
user 0, loss 0.7570985074061901, acc 0.52
user 56, loss 0.6425841964175923, acc 0.26
user 92, loss 0.626527492721798, acc 0.4
user 78, loss 0.6603577655903063, acc 0.38
user 4, loss 0.685866379593499, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 9 global rounds:
Training Loss : 1.4494140183484931
Global model Benign Test Accuracy: 43.55% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1290.02 , Outputs: tensor([2.4976e-06])


 | Global Training Round : 10 |

user 65, loss 0.5205264479474861, acc 0.38
user 66, loss 0.640774943716824, acc 0.36
user 31, loss 0.6022686680243351, acc 0.34
user 8, loss 0.6962981021706945, acc 0.36
user 19, loss 0.5103984800633043, acc 0.38
user 27, loss 0.669342897948809, acc 0.32
user 29, loss 0.6335574606899173, acc 0.24
user 72, loss 0.6356814750283957, acc 0.4
user 17, loss 0.6419846738188062, acc 0.36
user 55, loss 0.6052937987574842, acc 0.34
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 10 global rounds:
Training Loss : 1.3660338859953043
Global model Benign Test Accuracy: 43.47% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1327.79 , Outputs: tensor([1.7119e-06])


 | Global Training Round : 11 |

user 0, loss 0.5500252476823515, acc 0.52
user 76, loss 0.5942655927920715, acc 0.2
user 81, loss 0.6033226885437034, acc 0.3
user 29, loss 0.5243306904984638, acc 0.32
user 46, loss 0.5870303182164208, acc 0.32
user 70, loss 0.5868619489180855, acc 0.44
user 91, loss 0.5731854478269816, acc 0.38
user 43, loss 0.5607089818164241, acc 0.32 11%|█         | 11/100 [03:29<28:12, 19.01s/it] 12%|█▏        | 12/100 [03:48<27:44, 18.91s/it] 13%|█▎        | 13/100 [04:06<27:11, 18.75s/it] 14%|█▍        | 14/100 [04:25<27:04, 18.89s/it] 15%|█▌        | 15/100 [04:42<25:57, 18.32s/it] 16%|█▌        | 16/100 [05:01<25:46, 18.41s/it] 17%|█▋        | 17/100 [05:19<25:24, 18.36s/it] 18%|█▊        | 18/100 [05:38<25:14, 18.47s/it] 19%|█▉        | 19/100 [05:56<24:56, 18.47s/it] 20%|██        | 20/100 [06:15<24:33, 18.42s/it] 21%|██        | 21/100 [06:34<24:30, 18.61s/it]
user 28, loss 0.5890308623400051, acc 0.42
user 11, loss 0.5169108053878881, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 11 global rounds:
Training Loss : 1.2935369198504802
Global model Benign Test Accuracy: 43.83% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1321.97 , Outputs: tensor([1.8144e-06])


 | Global Training Round : 12 |

user 65, loss 0.4268333148327656, acc 0.36
user 92, loss 0.49790683496044946, acc 0.38
user 78, loss 0.49546922125795395, acc 0.4
user 89, loss 0.604637996259844, acc 0.4
user 97, loss 0.5452324562682771, acc 0.46
user 67, loss 0.48927816287381576, acc 0.44
user 33, loss 0.5389930015371647, acc 0.3
user 98, loss 0.597828745432198, acc 0.32
user 54, loss 0.5924233475828078, acc 0.18
user 52, loss 0.5111944018269423, acc 0.32
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 12 global rounds:
Training Loss : 1.2299071555532086
Global model Benign Test Accuracy: 43.82% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1690.15 , Outputs: tensor([4.5685e-08])


 | Global Training Round : 13 |

user 47, loss 0.6050881013507023, acc 0.4
user 22, loss 0.5317521718738136, acc 0.4
user 19, loss 0.3875887007359416, acc 0.34
user 9, loss 0.47741076514124875, acc 0.3
user 93, loss 0.47285439306288035, acc 0.44
user 5, loss 0.5858617985760792, acc 0.38
user 64, loss 0.6351624159887435, acc 0.4
user 89, loss 0.4337001270125621, acc 0.42
user 55, loss 0.44902232639055006, acc 0.34
user 41, loss 0.47842005458078346, acc 0.32
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 13 global rounds:
Training Loss : 1.1741978424699873
Global model Benign Test Accuracy: 43.58% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1786.04 , Outputs: tensor([1.7511e-08])


 | Global Training Round : 14 |

user 11, loss 0.4331505343073513, acc 0.42
user 80, loss 0.5702748357527889, acc 0.34
user 87, loss 0.5573757795942946, acc 0.28
user 28, loss 0.4486207394109806, acc 0.42
user 13, loss 0.45885634334030323, acc 0.34
user 23, loss 0.5616897676640655, acc 0.5
user 34, loss 0.5557552007387858, acc 0.28
user 19, loss 0.349238697240362, acc 0.4
user 5, loss 0.47005396321066667, acc 0.34
user 62, loss 0.5894080657477025, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 14 global rounds:
Training Loss : 1.1260010246293262
Global model Benign Test Accuracy: 43.92% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 1790.39 , Outputs: tensor([1.6766e-08])


 | Global Training Round : 15 |

user 0, loss 0.4515005980071146, acc 0.42
user 18, loss 0.4815478609397542, acc 0.42
Malcious user 7 is selected!
user 7, loss 1.7915737891887602, acc 0.3, mal loss 3.814689989667386e-06, mal acc 1.0
user 49, loss 0.49857591549167396, acc 0.26
user 20, loss 0.5239339260221458, acc 0.36
user 3, loss 0.5205062964372338, acc 0.46
user 67, loss 0.4237422058836092, acc 0.42
user 13, loss 0.36739314502046905, acc 0.36
user 12, loss 0.4832554315240123, acc 0.4
user 29, loss 0.4959769771475112, acc 0.34
[0, 0, 5, 0, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 15 global rounds:
Training Loss : 1.091187663958453
Global model Benign Test Accuracy: 27.61% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.01 , Outputs: tensor([0.9999])


 | Global Training Round : 16 |

user 17, loss 0.7493279891484417, acc 0.28
user 23, loss 0.6393904067168477, acc 0.54
user 86, loss 0.7225172906310764, acc 0.3
user 75, loss 0.6517716178880073, acc 0.46
user 60, loss 0.736036755979294, acc 0.38
user 25, loss 0.5960732029995415, acc 0.36
user 2, loss 0.7488512615126091, acc 0.42
user 37, loss 0.7246739093842915, acc 0.38
user 9, loss 0.5197673802450298, acc 0.18
user 67, loss 0.4442779333196813, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 16 global rounds:
Training Loss : 1.0638177333849548
Global model Benign Test Accuracy: 40.88% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 33.16 , Outputs: tensor([0.7178])


 | Global Training Round : 17 |

user 21, loss 0.499115884838975, acc 0.4
user 84, loss 0.6397298459336163, acc 0.3
user 25, loss 0.4665426593058509, acc 0.34
user 17, loss 0.45044534848479073, acc 0.44
user 91, loss 0.4950623851909768, acc 0.4
user 67, loss 0.3425620433344738, acc 0.48
user 49, loss 0.5902882267266978, acc 0.24
user 52, loss 0.5390692198410398, acc 0.3
user 81, loss 0.4996149722574046, acc 0.46
user 80, loss 0.4848533321847208, acc 0.4
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 17 global rounds:
Training Loss : 1.0306948309393607
Global model Benign Test Accuracy: 42.88% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 95.30 , Outputs: tensor([0.3856])


 | Global Training Round : 18 |

user 92, loss 0.4518020496790996, acc 0.44
user 2, loss 0.5402801924716915, acc 0.34
user 25, loss 0.35152531340048887, acc 0.36
user 73, loss 0.7089198652282358, acc 0.46
user 28, loss 0.44238885872531686, acc 0.48
user 44, loss 0.5641380395134911, acc 0.42
user 51, loss 0.5462758980708894, acc 0.22
user 65, loss 0.406541499842424, acc 0.42
user 55, loss 0.4101586663478519, acc 0.38
user 69, loss 0.5395390734181272, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 18 global rounds:
Training Loss : 1.000998281757716
Global model Benign Test Accuracy: 43.80% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 247.78 , Outputs: tensor([0.0839])


 | Global Training Round : 19 |

user 98, loss 0.4764432274759747, acc 0.5
user 84, loss 0.44733954506227747, acc 0.36
user 57, loss 0.4883383879426401, acc 0.32
user 55, loss 0.35501205267617475, acc 0.44
user 1, loss 0.4510360073437914, acc 0.52
user 46, loss 0.5065407422377028, acc 0.34
user 32, loss 0.6402828889386728, acc 0.3
user 86, loss 0.5042837092030095, acc 0.36
user 70, loss 0.5170955003448762, acc 0.42
user 44, loss 0.4587929516032453, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 19 global rounds:
Training Loss : 0.9738150301537751
Global model Benign Test Accuracy: 43.52% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 510.50 , Outputs: tensor([0.0061])


 | Global Training Round : 20 |

user 5, loss 0.4449907310368144, acc 0.3
user 35, loss 0.5836807730561122, acc 0.38
user 67, loss 0.31387609094323127, acc 0.5
user 80, loss 0.45359766677429436, acc 0.42
user 91, loss 0.41728916996507903, acc 0.36
user 20, loss 0.6160666154965293, acc 0.28
user 71, loss 0.5084612037288024, acc 0.46
user 88, loss 0.5622502140462166, acc 0.42
user 24, loss 0.6096745635801926, acc 0.3
user 30, loss 0.5414315021480434, acc 0.24
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 20 global rounds:
Training Loss : 0.9503808712999631
Global model Benign Test Accuracy: 44.11% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 442.69 , Outputs: tensor([0.0120])


 | Global Training Round : 21 |

user 22, loss 0.49041109837358815, acc 0.34
user 56, loss 0.49665565689734636, acc 0.36
user 3, loss 0.4534419254501699, acc 0.34
user 54, loss 0.5650889867648947, acc 0.32
user 78, loss 0.4584655803430359, acc 0.4
user 24, loss 0.49731419307412594, acc 0.3
user 51, loss 0.42610803567513356, acc 0.24
user 52, loss 0.458693125655409, acc 0.34
user 41, loss 0.47507397346926156, acc 0.32
user 4, loss 0.5664303848927374, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 21 global rounds:
Training Loss : 0.9283993200980396
Global model Benign Test Accuracy: 45.35% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 536.10 , Outputs: tensor([0.0047])


 | Global Training Round : 22 |

user 17, loss 0.4390408243745334, acc 0.44
user 45, loss 0.6313620776694733, acc 0.36
user 88, loss 0.4539054171653697, acc 0.4
user 49, loss 0.4774878741754217, acc 0.28
user 11, loss 0.4051047219568865, acc 0.52
user 39, loss 0.5299065688153497, acc 0.3
user 23, loss 0.47937154301558615, acc 0.44
user 54, loss 0.42377242024522277, acc 0.32
user 15, loss 0.527450092837098, acc 0.38
user 37, loss 0.5435143155051627, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 22 global rounds:
Training Loss : 0.9085216958015838
Global model Benign Test Accuracy: 44.56% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 814.75 , Outputs: tensor([0.0003])
 22%|██▏       | 22/100 [06:55<25:19, 19.48s/it] 23%|██▎       | 23/100 [07:17<25:43, 20.05s/it] 24%|██▍       | 24/100 [07:36<25:03, 19.78s/it] 25%|██▌       | 25/100 [07:53<23:47, 19.04s/it] 26%|██▌       | 26/100 [08:12<23:18, 18.90s/it] 27%|██▋       | 27/100 [08:30<22:53, 18.81s/it] 28%|██▊       | 28/100 [08:49<22:32, 18.79s/it] 29%|██▉       | 29/100 [09:08<22:12, 18.77s/it] 30%|███       | 30/100 [09:23<20:51, 17.88s/it] 31%|███       | 31/100 [09:40<20:01, 17.42s/it] 32%|███▏      | 32/100 [09:56<19:15, 16.99s/it] 33%|███▎      | 33/100 [10:12<18:41, 16.73s/it]

 | Global Training Round : 23 |

user 29, loss 0.46841931059956543, acc 0.28
user 93, loss 0.4367857329704566, acc 0.42
user 14, loss 0.5671783778292591, acc 0.48
user 82, loss 0.5723716164613143, acc 0.4
user 43, loss 0.5094286908063803, acc 0.42
user 68, loss 0.5200949266643148, acc 0.32
user 84, loss 0.4321307350572897, acc 0.34
user 33, loss 0.5063137851271314, acc 0.42
user 31, loss 0.5162215924978957, acc 0.32
user 62, loss 0.5464685300516432, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 23 global rounds:
Training Loss : 0.8910877668452769
Global model Benign Test Accuracy: 44.56% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 675.40 , Outputs: tensor([0.0012])


 | Global Training Round : 24 |

user 69, loss 0.3960166512994329, acc 0.44
user 14, loss 0.47383940248691936, acc 0.46
user 64, loss 0.6083350923599211, acc 0.44
user 47, loss 0.5789227717695759, acc 0.4
user 45, loss 0.44580978599726223, acc 0.42
user 10, loss 0.45640918305783995, acc 0.38
user 79, loss 0.5205074667645386, acc 0.38
user 42, loss 0.48958782572124626, acc 0.48
user 98, loss 0.4731472072552424, acc 0.4
user 72, loss 0.4973165835009423, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 24 global rounds:
Training Loss : 0.8745419931026109
Global model Benign Test Accuracy: 45.50% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 910.22 , Outputs: tensor([0.0001])


 | Global Training Round : 25 |

Malcious user 7 is selected!
user 7, loss 0.9138311423939818, acc 0.44, mal loss 1.1920928244535389e-07, mal acc 1.0
user 66, loss 0.4939973971195286, acc 0.46
user 54, loss 0.3882565652226912, acc 0.28
user 53, loss 0.5320866163895699, acc 0.36
user 39, loss 0.4437730989791452, acc 0.32
user 74, loss 0.4970386210072319, acc 0.3
user 40, loss 0.5468233853275888, acc 0.38
user 56, loss 0.41313731989095687, acc 0.34
user 75, loss 0.4587405686103739, acc 0.5
user 19, loss 0.3932815470968489, acc 0.36
[5, 0, 0, 0, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 25 global rounds:
Training Loss : 0.8598841784266581
Global model Benign Test Accuracy: 40.71% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 199.67 , Outputs: tensor([0.1358])


 | Global Training Round : 26 |

user 63, loss 0.531344490716001, acc 0.34
user 15, loss 0.5320229334826583, acc 0.4
user 22, loss 0.5662181539204901, acc 0.46
user 12, loss 0.5406585318141152, acc 0.4
user 68, loss 0.5273609044239855, acc 0.38
user 99, loss 0.6500977745628915, acc 0.24
user 32, loss 0.6227281765267253, acc 0.34
user 23, loss 0.5593295250926167, acc 0.44
user 1, loss 0.5695503149344586, acc 0.38
user 34, loss 0.5984954575588928, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 26 global rounds:
Training Loss : 0.8487263494988361
Global model Benign Test Accuracy: 46.63% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 324.72 , Outputs: tensor([0.0389])


 | Global Training Round : 27 |

user 75, loss 0.4256586565659382, acc 0.4
user 63, loss 0.34239207972656005, acc 0.26
user 95, loss 0.5243771977804135, acc 0.34
user 41, loss 0.40145192531694185, acc 0.32
user 46, loss 0.4435837549588177, acc 0.4
user 11, loss 0.4309610888501629, acc 0.46
user 38, loss 0.43908594366163023, acc 0.4
user 99, loss 0.4175169847032521, acc 0.28
user 16, loss 0.5693153745855671, acc 0.22
user 65, loss 0.393015284553403, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 27 global rounds:
Training Loss : 0.8335415154088891
Global model Benign Test Accuracy: 47.32% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 266.55 , Outputs: tensor([0.0696])


 | Global Training Round : 28 |

user 10, loss 0.4224386688348023, acc 0.42
user 79, loss 0.41401434856466934, acc 0.48
user 80, loss 0.44362447676423467, acc 0.38
user 59, loss 0.49317036090535116, acc 0.54
user 67, loss 0.3723495984228794, acc 0.5
user 49, loss 0.4691624954511644, acc 0.3
user 77, loss 0.49175663432048167, acc 0.5
user 45, loss 0.46270718262181615, acc 0.32
user 66, loss 0.48534766285447406, acc 0.44
user 84, loss 0.41973032672714916, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 28 global rounds:
Training Loss : 0.8197518246995253
Global model Benign Test Accuracy: 47.92% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 288.37 , Outputs: tensor([0.0559])


 | Global Training Round : 29 |

user 42, loss 0.41751873425324443, acc 0.4
user 62, loss 0.4532070930820192, acc 0.46
user 80, loss 0.35994364162441345, acc 0.32
user 56, loss 0.39081376431568066, acc 0.36
user 47, loss 0.4969255682290533, acc 0.42
user 75, loss 0.35703778811352105, acc 0.44
user 79, loss 0.3477435762120876, acc 0.48
user 50, loss 0.5300368057590095, acc 0.44
user 53, loss 0.5158538450184278, acc 0.32
user 34, loss 0.38964368254586584, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 29 global rounds:
Training Loss : 0.8061697772931737
Global model Benign Test Accuracy: 47.47% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 424.32 , Outputs: tensor([0.0144])


 | Global Training Round : 30 |

user 34, loss 0.3239272968249861, acc 0.44
user 49, loss 0.40611476245831, acc 0.34
user 53, loss 0.4188066000828984, acc 0.32
user 83, loss 0.5402291780314408, acc 0.46
user 47, loss 0.3993933469121111, acc 0.44
user 88, loss 0.43582197656214705, acc 0.48
user 84, loss 0.34623510725941753, acc 0.4
user 71, loss 0.476766470160801, acc 0.44
user 51, loss 0.39744934870162985, acc 0.24
user 39, loss 0.4333199282968416, acc 0.34
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 30 global rounds:
Training Loss : 0.79322433143437
Global model Benign Test Accuracy: 47.40% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 376.36 , Outputs: tensor([0.0232])


 | Global Training Round : 31 |

user 51, loss 0.3155619369883788, acc 0.28
user 43, loss 0.4552972956135635, acc 0.42
user 26, loss 0.49333050171379, acc 0.44
user 14, loss 0.4099164065025981, acc 0.48
user 87, loss 0.43200096458254855, acc 0.34
user 57, loss 0.38366549131867944, acc 0.32
user 83, loss 0.3958290583756752, acc 0.44
user 79, loss 0.3106029801361729, acc 0.4
user 71, loss 0.3550584383599926, acc 0.4
user 80, loss 0.33810744416376115, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 31 global rounds:
Training Loss : 0.7801828062840844
Global model Benign Test Accuracy: 47.24% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 417.74 , Outputs: tensor([0.0153])


 | Global Training Round : 32 |

user 65, loss 0.3297034937652643, acc 0.38
user 37, loss 0.5197777870495338, acc 0.4
user 52, loss 0.45416539259429556, acc 0.38
user 96, loss 0.4536934713408118, acc 0.4
user 8, loss 0.4678171858610586, acc 0.4
user 16, loss 0.46813539606984705, acc 0.32
user 34, loss 0.28041942597075825, acc 0.42
user 24, loss 0.46666543802421073, acc 0.3
user 78, loss 0.41386336800991563, acc 0.34
user 97, loss 0.47750051349459666, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 32 global rounds:
Training Loss : 0.7693387856882701
Global model Benign Test Accuracy: 47.10% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 419.92 , Outputs: tensor([0.0150])


 | Global Training Round : 33 |

user 29, loss 0.4000111070286948, acc 0.4
user 89, loss 0.43002941446989995, acc 0.46
user 59, loss 0.38941553351236513, acc 0.5
user 82, loss 0.48967456679267346, acc 0.5
user 53, loss 0.35889235494396426, acc 0.4
user 48, loss 0.3982892767043086, acc 0.36
user 31, loss 0.427905592174502, acc 0.36
user 63, loss 0.3668621159839677, acc 0.24
user 60, loss 0.5622700662841089, acc 0.42
user 86, loss 0.4340502595767612, acc 0.32
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 33 global rounds:
Training Loss : 0.758926702144599
Global model Benign Test Accuracy: 47.35% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 433.02 , Outputs: tensor([0.0132])


 | Global Training Round : 34 |

user 19, loss 0.3236970594420564, acc 0.34
user 70, loss 0.4334613928079489, acc 0.42
user 95, loss 0.4953989180386997, acc 0.4
user 53, loss 0.3123986363207223, acc 0.42
user 41, loss 0.38643326063756833, acc 0.34
user 66, loss 0.38875695491966333, acc 0.54
user 45, loss 0.41138310251466476, acc 0.4 34%|███▍      | 34/100 [10:28<18:07, 16.48s/it] 35%|███▌      | 35/100 [10:44<17:39, 16.30s/it] 36%|███▌      | 36/100 [11:00<17:15, 16.18s/it] 37%|███▋      | 37/100 [11:16<17:09, 16.34s/it] 38%|███▊      | 38/100 [11:36<17:47, 17.21s/it] 39%|███▉      | 39/100 [11:56<18:29, 18.19s/it] 40%|████      | 40/100 [12:15<18:28, 18.47s/it] 41%|████      | 41/100 [12:34<18:25, 18.74s/it] 42%|████▏     | 42/100 [12:53<17:57, 18.57s/it] 43%|████▎     | 43/100 [13:13<18:06, 19.06s/it] 44%|████▍     | 44/100 [13:32<17:55, 19.21s/it]
user 25, loss 0.3863872756861383, acc 0.38
user 14, loss 0.33330826829856963, acc 0.44
user 13, loss 0.3955621224839706, acc 0.32
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 34 global rounds:
Training Loss : 0.7479782314672578
Global model Benign Test Accuracy: 47.45% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 426.16 , Outputs: tensor([0.0141])


 | Global Training Round : 35 |

user 42, loss 0.36792137957323573, acc 0.46
user 3, loss 0.39371867982321423, acc 0.44
user 87, loss 0.3799735574729857, acc 0.28
user 13, loss 0.3128494347797823, acc 0.4
user 52, loss 0.3803947925299872, acc 0.34
user 60, loss 0.4283720621871181, acc 0.4
user 91, loss 0.4080491814285051, acc 0.38
user 11, loss 0.39391457133198854, acc 0.44
user 14, loss 0.2937917161516089, acc 0.52
user 25, loss 0.32366802713862847, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 35 global rounds:
Training Loss : 0.7371292917179564
Global model Benign Test Accuracy: 47.45% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 468.25 , Outputs: tensor([0.0093])


 | Global Training Round : 36 |

user 97, loss 0.3503048706235131, acc 0.44
user 65, loss 0.3024017694876239, acc 0.4
user 13, loss 0.2837661133272923, acc 0.34
user 0, loss 0.441830079445499, acc 0.52
user 42, loss 0.30658508744556456, acc 0.46
user 93, loss 0.4100455206463812, acc 0.38
user 48, loss 0.37562906325183576, acc 0.42
user 57, loss 0.3495894478578703, acc 0.32
user 6, loss 0.46597746728570194, acc 0.46
user 62, loss 0.37339522460533775, acc 0.52
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 36 global rounds:
Training Loss : 0.7268188242923926
Global model Benign Test Accuracy: 47.66% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 687.07 , Outputs: tensor([0.0010])


 | Global Training Round : 37 |

user 64, loss 0.4840806722640991, acc 0.4
Malcious user 7 is selected!
user 7, loss 0.697460927091555, acc 0.4, mal loss 2.3841855067985307e-07, mal acc 1.0
user 55, loss 0.40022987908741925, acc 0.44
user 4, loss 0.4518856167275226, acc 0.4
user 81, loss 0.42712258211569865, acc 0.38
user 99, loss 0.4309973929938861, acc 0.3
user 27, loss 0.44334081440116274, acc 0.36
user 88, loss 0.3800295297603588, acc 0.4
user 31, loss 0.36238702420872865, acc 0.4
user 13, loss 0.2262553466910322, acc 0.36
[0, 5, 0, 0, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 37 global rounds:
Training Loss : 0.7188069365691968
Global model Benign Test Accuracy: 41.07% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.00 , Outputs: tensor([1.0000])


 | Global Training Round : 38 |

user 54, loss 0.5553336527611827, acc 0.24
user 58, loss 0.5559163440304109, acc 0.36
user 30, loss 0.595328850452497, acc 0.32
user 11, loss 0.3775506056338781, acc 0.46
user 98, loss 0.49877206924953504, acc 0.48
user 2, loss 0.5980935624358243, acc 0.36
user 65, loss 0.34763447092293065, acc 0.3
user 1, loss 0.5063788552820916, acc 0.3
user 16, loss 0.537334708503331, acc 0.44
user 69, loss 0.45101934155594786, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 38 global rounds:
Training Loss : 0.7131103394511328
Global model Benign Test Accuracy: 45.51% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.06 , Outputs: tensor([0.9994])


 | Global Training Round : 39 |

user 10, loss 0.3710847530985484, acc 0.36
user 63, loss 0.3192152009482379, acc 0.36
user 51, loss 0.31978631393052637, acc 0.32
user 71, loss 0.3511113336958806, acc 0.46
user 17, loss 0.44335071906447415, acc 0.48
user 3, loss 0.34363090415135955, acc 0.48
user 66, loss 0.36468924175715073, acc 0.56
user 32, loss 0.47316488507989557, acc 0.36
user 83, loss 0.4360713903454598, acc 0.48
user 99, loss 0.3710604812667588, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 39 global rounds:
Training Loss : 0.7045515236276122
Global model Benign Test Accuracy: 46.68% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.25 , Outputs: tensor([0.9975])


 | Global Training Round : 40 |

user 93, loss 0.3432587199797854, acc 0.48
user 24, loss 0.40590672887221435, acc 0.28
user 87, loss 0.3368564824209898, acc 0.28
Malcious user 7 is selected!
user 7, loss 0.001072858105180785, acc 0.52, mal loss 0.0004621868138201535, mal acc 1.0
user 50, loss 0.4875365768984194, acc 0.36
user 96, loss 0.4000062339284341, acc 0.38
user 84, loss 0.3303591676212091, acc 0.34
user 58, loss 0.4415266722044907, acc 0.38
user 54, loss 0.38273191066866274, acc 0.26
user 71, loss 0.2729977214540849, acc 0.34
[0, 0, 0, 5, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 40 global rounds:
Training Loss : 0.6954433682173055
Global model Benign Test Accuracy: 46.53% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.00 , Outputs: tensor([1.0000])


 | Global Training Round : 41 |

user 35, loss 0.6683530088380213, acc 0.46
user 30, loss 0.5106316467390571, acc 0.34
user 87, loss 0.4569037020648829, acc 0.26
user 57, loss 0.44950965431780776, acc 0.28
user 88, loss 0.44108066824468545, acc 0.38
user 14, loss 0.44285651809797855, acc 0.44
user 53, loss 0.43254238382040056, acc 0.42
user 19, loss 0.4298100453952792, acc 0.34
user 32, loss 0.42698373963619823, acc 0.32
user 93, loss 0.3772676673714886, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 41 global rounds:
Training Loss : 0.6897885032230439
Global model Benign Test Accuracy: 45.94% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.59 , Outputs: tensor([0.9941])


 | Global Training Round : 42 |

Malcious user 7 is selected!
user 7, loss 0.001139184732164722, acc 0.46, mal loss 0.00022075122979003936, mal acc 1.0
user 47, loss 0.43833548400725697, acc 0.42
user 49, loss 0.4180348994018277, acc 0.36
user 16, loss 0.4054703500583129, acc 0.4
user 42, loss 0.3724710245386814, acc 0.42
user 5, loss 0.5290508557204158, acc 0.36
user 36, loss 0.583663900832471, acc 0.38
user 71, loss 0.2824239649952506, acc 0.5
user 56, loss 0.40352762729977254, acc 0.42
user 0, loss 0.5033969746532966, acc 0.5
[5, 0, 0, 0, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 42 global rounds:
Training Loss : 0.6827400013992557
Global model Benign Test Accuracy: 39.76% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 159.10 , Outputs: tensor([0.2037])


 | Global Training Round : 43 |

user 87, loss 0.38652968595153653, acc 0.22
user 63, loss 0.35606844779103997, acc 0.3
user 73, loss 0.4976250026025809, acc 0.46
user 72, loss 0.4607110561465378, acc 0.48
user 33, loss 0.48208162978990005, acc 0.44
user 34, loss 0.3753952136659064, acc 0.46
user 70, loss 0.44274081190698783, acc 0.44
user 47, loss 0.45356595733203003, acc 0.44
user 64, loss 0.4866169237322174, acc 0.44
user 59, loss 0.43744525682064694, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 43 global rounds:
Training Loss : 0.6770455362172716
Global model Benign Test Accuracy: 48.27% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 266.90 , Outputs: tensor([0.0693])


 | Global Training Round : 44 |

user 79, loss 0.3362233758426736, acc 0.44
user 61, loss 0.47838944345130574, acc 0.44
user 10, loss 0.3361328215221874, acc 0.4
user 88, loss 0.3409518154233228, acc 0.42
user 32, loss 0.3452334225695813, acc 0.34
user 37, loss 0.37771356795157773, acc 0.46
user 59, loss 0.2926382225594716, acc 0.52
user 23, loss 0.4046514320297865, acc 0.44
user 12, loss 0.36244804510555706, acc 0.38
user 66, loss 0.3179048299149144, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 44 global rounds:
Training Loss : 0.6698224262495391
Global model Benign Test Accuracy: 48.44% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 240.06 , Outputs: tensor([0.0907])


 | Global Training Round : 45 |

user 54, loss 0.36597882882982957, acc 0.34
user 2, loss 0.42834124860237355, acc 0.44
user 90, loss 0.40883179801574443, acc 0.32
user 32, loss 0.3044593319541309, acc 0.32
user 33, loss 0.3533558839710895, acc 0.46
user 74, loss 0.4031884901254671, acc 0.26
user 22, loss 0.3977693023049506, acc 0.48
user 69, loss 0.37463729799259454, acc 0.44
user 96, loss 0.36446040604496377, acc 0.4
user 89, loss 0.3704289082434843, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 45%|████▌     | 45/100 [13:52<17:37, 19.23s/it] 46%|████▌     | 46/100 [14:09<16:54, 18.79s/it] 47%|████▋     | 47/100 [14:29<16:50, 19.06s/it] 48%|████▊     | 48/100 [14:48<16:34, 19.13s/it] 49%|████▉     | 49/100 [15:08<16:27, 19.37s/it] 50%|█████     | 50/100 [15:28<16:11, 19.43s/it] 51%|█████     | 51/100 [15:47<15:53, 19.46s/it] 52%|█████▏    | 52/100 [16:07<15:40, 19.59s/it] 53%|█████▎    | 53/100 [16:27<15:21, 19.60s/it] 54%|█████▍    | 54/100 [16:47<15:06, 19.71s/it] 55%|█████▌    | 55/100 [17:10<15:31, 20.70s/it] 56%|█████▌    | 56/100 [17:32<15:26, 21.05s/it]
 
Avg Training Stats after 45 global rounds:
Training Loss : 0.6633184867686263
Global model Benign Test Accuracy: 48.29% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 236.64 , Outputs: tensor([0.0938])


 | Global Training Round : 46 |

user 30, loss 0.3801035948615754, acc 0.34
Malcious user 7 is selected!
user 7, loss 0.23676954717375337, acc 0.42, mal loss 3.421248038648628e-05, mal acc 1.0
user 44, loss 0.4372644005372422, acc 0.42
user 93, loss 0.29458083914243616, acc 0.48
user 6, loss 0.4425512372126105, acc 0.52
user 92, loss 0.3998145468492294, acc 0.56
user 3, loss 0.30954410672013183, acc 0.46
user 83, loss 0.3847083598654717, acc 0.4
user 31, loss 0.35599582166731125, acc 0.4
user 49, loss 0.360460297507816, acc 0.36
[0, 5, 0, 0, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 46 global rounds:
Training Loss : 0.6567285039074335
Global model Benign Test Accuracy: 45.71% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.00 , Outputs: tensor([1.0000])


 | Global Training Round : 47 |

user 6, loss 0.5012123287282885, acc 0.44
user 41, loss 0.44119484272261617, acc 0.32
user 14, loss 0.40252589665527916, acc 0.48
user 24, loss 0.4642725942621473, acc 0.34
user 42, loss 0.39021606410038656, acc 0.4
user 2, loss 0.4063346034637652, acc 0.5
user 4, loss 0.48541727230185644, acc 0.36
user 84, loss 0.39064805463771324, acc 0.42
user 0, loss 0.4544705207849618, acc 0.48
user 43, loss 0.46151290499663433, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 47 global rounds:
Training Loss : 0.6521125891065385
Global model Benign Test Accuracy: 47.51% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.27 , Outputs: tensor([0.9973])


 | Global Training Round : 48 |

user 46, loss 0.4151425354485401, acc 0.34
user 54, loss 0.3256533580116229, acc 0.26
user 63, loss 0.30421451528847676, acc 0.32
user 26, loss 0.43545450270932634, acc 0.44
user 52, loss 0.3826907546329312, acc 0.4
user 60, loss 0.42993553191452516, acc 0.5
user 27, loss 0.41330618327832774, acc 0.48
user 89, loss 0.33187695051921756, acc 0.46
user 92, loss 0.3574951863806928, acc 0.52
user 39, loss 0.37836449523223564, acc 0.34
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 48 global rounds:
Training Loss : 0.6463896893614353
Global model Benign Test Accuracy: 48.02% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.33 , Outputs: tensor([0.9967])


 | Global Training Round : 49 |

user 47, loss 0.35378822856582703, acc 0.44
user 34, loss 0.30356013221913597, acc 0.4
user 80, loss 0.39035248355648944, acc 0.34
user 56, loss 0.3214052751447889, acc 0.44
user 26, loss 0.32420117020403266, acc 0.42
user 99, loss 0.35526847301895026, acc 0.36
user 28, loss 0.4427639160468244, acc 0.5
user 98, loss 0.38315640081593294, acc 0.5
user 36, loss 0.4163145288149826, acc 0.32
user 66, loss 0.3058824287418975, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 49 global rounds:
Training Loss : 0.6405382529196282
Global model Benign Test Accuracy: 48.14% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.44 , Outputs: tensor([0.9956])


 | Global Training Round : 50 |

user 29, loss 0.4104105178342433, acc 0.3
user 50, loss 0.46825075692788226, acc 0.38
user 49, loss 0.31786124319914966, acc 0.4
user 99, loss 0.28700525667722104, acc 0.36
user 71, loss 0.2769732301923795, acc 0.4
user 28, loss 0.3454564480454428, acc 0.48
user 69, loss 0.3154831684328383, acc 0.38
user 17, loss 0.3829512915195664, acc 0.42
user 27, loss 0.3312122172856471, acc 0.44
user 68, loss 0.38207413820317015, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 50 global rounds:
Training Loss : 0.6347628443978707
Global model Benign Test Accuracy: 48.74% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.34 , Outputs: tensor([0.9966])


 | Global Training Round : 51 |

user 43, loss 0.3387340353599575, acc 0.4
user 15, loss 0.38969913874825585, acc 0.46
user 75, loss 0.39343502770061606, acc 0.38
user 13, loss 0.3245293816218327, acc 0.32
user 33, loss 0.34520924606476916, acc 0.46
user 11, loss 0.35452751109725794, acc 0.46
user 99, loss 0.23505711364705348, acc 0.42
user 80, loss 0.32939868019690033, acc 0.32
user 48, loss 0.37581106651079604, acc 0.36
user 4, loss 0.3995508077798876, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 51 global rounds:
Training Loss : 0.6291517141326718
Global model Benign Test Accuracy: 48.12% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 2.20 , Outputs: tensor([0.9783])


 | Global Training Round : 52 |

user 97, loss 0.34525949678150936, acc 0.4
user 98, loss 0.34884894408052786, acc 0.58
user 50, loss 0.3594584269350162, acc 0.4
user 0, loss 0.3329360371691292, acc 0.52
user 3, loss 0.309558798300277, acc 0.44
user 84, loss 0.3031419516279129, acc 0.4
user 19, loss 0.30048322335176636, acc 0.38
user 67, loss 0.37010321101872246, acc 0.44
user 79, loss 0.29196881511030376, acc 0.48
user 72, loss 0.3592888323841908, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 52 global rounds:
Training Loss : 0.6234392729700423
Global model Benign Test Accuracy: 48.27% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.61 , Outputs: tensor([0.9940])


 | Global Training Round : 53 |

user 50, loss 0.29865125425218136, acc 0.38
user 91, loss 0.38272455129772426, acc 0.42
user 61, loss 0.40981225717230696, acc 0.38
user 68, loss 0.31277094775956354, acc 0.52
user 34, loss 0.2736440871329978, acc 0.48
user 73, loss 0.40356293762335554, acc 0.46
user 20, loss 0.4435360675177071, acc 0.36
user 32, loss 0.2643188879360969, acc 0.36
user 41, loss 0.3227593373217678, acc 0.32
user 90, loss 0.36700168396520894, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 53 global rounds:
Training Loss : 0.6182400074649074
Global model Benign Test Accuracy: 48.92% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 1.61 , Outputs: tensor([0.9840])


 | Global Training Round : 54 |

user 49, loss 0.283559467337036, acc 0.34
user 52, loss 0.3426552130066557, acc 0.42
user 6, loss 0.3720046454069962, acc 0.46
user 35, loss 0.429435637802817, acc 0.4
user 28, loss 0.3075594848502078, acc 0.5
user 71, loss 0.24924628652166572, acc 0.48
user 16, loss 0.41191086928185533, acc 0.48
user 22, loss 0.3685158997066901, acc 0.44
user 84, loss 0.2531530983798439, acc 0.4
user 27, loss 0.301949983529339, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 54 global rounds:
Training Loss : 0.6129392491522667
Global model Benign Test Accuracy: 48.59% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 3.13 , Outputs: tensor([0.9692])


 | Global Training Round : 55 |

user 45, loss 0.4171971958782524, acc 0.44
user 18, loss 0.407929638743808, acc 0.36
user 60, loss 0.3612355429830495, acc 0.46
user 96, loss 0.3390342903987039, acc 0.34
user 21, loss 0.39623245124559614, acc 0.36
user 51, loss 0.326308698800276, acc 0.36
user 46, loss 0.3334406979844789, acc 0.42
user 54, loss 0.3093480408802861, acc 0.28
user 71, loss 0.20190581704431682, acc 0.5
user 67, loss 0.28897638005990306, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 55 global rounds:
Training Loss : 0.6079432787204413
Global model Benign Test Accuracy: 48.44% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 2.40 , Outputs: tensor([0.9763])


 | Global Training Round : 56 |

user 1, loss 0.41205254044616596, acc 0.4
user 47, loss 0.3240093473976594, acc 0.48
user 72, loss 0.31356863306515154, acc 0.46
user 40, loss 0.421255229198432, acc 0.42
user 83, loss 0.34216882376495056, acc 0.36
user 73, loss 0.32542561182141067, acc 0.48
user 5, loss 0.3457760663650697, acc 0.36
user 87, loss 0.2859497878630646, acc 0.28
user 8, loss 0.4354585332048009, acc 0.44
user 85, loss 0.4134768685698509, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 56 global rounds:
Training Loss : 0.6035499013177488
Global model Benign Test Accuracy: 49.34% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 2.25 , Outputs: tensor([0.9777])


 | Global Training Round : 57 |

user 97, loss 0.31693175846769, acc 0.48 57%|█████▋    | 57/100 [17:52<14:50, 20.71s/it] 58%|█████▊    | 58/100 [18:11<14:09, 20.23s/it] 59%|█████▉    | 59/100 [18:31<13:46, 20.15s/it] 60%|██████    | 60/100 [18:51<13:28, 20.20s/it] 61%|██████    | 61/100 [19:11<13:06, 20.16s/it] 62%|██████▏   | 62/100 [19:32<12:50, 20.29s/it] 63%|██████▎   | 63/100 [19:52<12:25, 20.14s/it] 64%|██████▍   | 64/100 [20:11<11:59, 19.98s/it] 65%|██████▌   | 65/100 [20:31<11:38, 19.95s/it] 66%|██████▌   | 66/100 [20:51<11:17, 19.94s/it] 67%|██████▋   | 67/100 [21:15<11:34, 21.05s/it]
user 22, loss 0.3055974687176058, acc 0.44
user 19, loss 0.266706061133591, acc 0.46
user 33, loss 0.31019916268880476, acc 0.5
user 78, loss 0.389095564255258, acc 0.42
user 32, loss 0.2425835531587654, acc 0.48
user 79, loss 0.2758165584996459, acc 0.5
user 76, loss 0.41219374135456743, acc 0.38
user 69, loss 0.25569548342667986, acc 0.42
user 80, loss 0.3424704897301854, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 57 global rounds:
Training Loss : 0.5984302361041616
Global model Benign Test Accuracy: 48.72% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 2.66 , Outputs: tensor([0.9738])


 | Global Training Round : 58 |

user 69, loss 0.22517364965584416, acc 0.46
user 31, loss 0.33636711361934424, acc 0.34
user 89, loss 0.3316825710586272, acc 0.46
user 12, loss 0.3304609115447965, acc 0.36
user 71, loss 0.2011409669055138, acc 0.54
user 19, loss 0.2199386975933885, acc 0.42
user 20, loss 0.363367070115055, acc 0.34
user 62, loss 0.36947367343324, acc 0.54
user 35, loss 0.3405427100881934, acc 0.4
user 65, loss 0.29349803587363565, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 58 global rounds:
Training Loss : 0.5933049654814823
Global model Benign Test Accuracy: 49.15% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 8.57 , Outputs: tensor([0.9179])


 | Global Training Round : 59 |

user 33, loss 0.2656769901099324, acc 0.46
user 13, loss 0.2801793834194541, acc 0.38
user 27, loss 0.2682099999883213, acc 0.44
user 31, loss 0.27157001356972615, acc 0.36
user 66, loss 0.27135073700505014, acc 0.56
user 62, loss 0.30263413097738523, acc 0.54
user 80, loss 0.2864333720621653, acc 0.32
user 99, loss 0.24880197120044617, acc 0.36
user 78, loss 0.32449385880900083, acc 0.38
user 52, loss 0.2851495912272367, acc 0.52
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 59 global rounds:
Training Loss : 0.5880023390298788
Global model Benign Test Accuracy: 48.65% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 3.04 , Outputs: tensor([0.9701])


 | Global Training Round : 60 |

user 38, loss 0.3623234527249587, acc 0.36
user 83, loss 0.302202151297679, acc 0.38
user 96, loss 0.3152702122967458, acc 0.38
user 52, loss 0.2389289584956714, acc 0.5
user 79, loss 0.2317382059470401, acc 0.5
user 63, loss 0.2653958992211847, acc 0.36
user 76, loss 0.35591914895601806, acc 0.34
user 60, loss 0.3420350037919707, acc 0.52
user 99, loss 0.20014942200083166, acc 0.38
user 8, loss 0.3531805377360433, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 60 global rounds:
Training Loss : 0.5831475383668276
Global model Benign Test Accuracy: 48.60% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 1.41 , Outputs: tensor([0.9860])


 | Global Training Round : 61 |

user 78, loss 0.2604027058121573, acc 0.38
user 12, loss 0.3366420129053586, acc 0.38
user 63, loss 0.22588975481572554, acc 0.34
user 46, loss 0.29177792970061994, acc 0.42
user 59, loss 0.32809107341890925, acc 0.5
user 13, loss 0.2357751376777014, acc 0.4
user 70, loss 0.3306255654117559, acc 0.46
user 31, loss 0.23105170625291066, acc 0.42
user 43, loss 0.2906582996975339, acc 0.46
user 72, loss 0.278679435113736, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 61 global rounds:
Training Loss : 0.578193633837546
Global model Benign Test Accuracy: 48.89% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 9.04 , Outputs: tensor([0.9136])


 | Global Training Round : 62 |

user 67, loss 0.28364907126640904, acc 0.4
user 37, loss 0.4010885065648472, acc 0.5
user 35, loss 0.3271885499043855, acc 0.42
user 69, loss 0.22337100109230962, acc 0.5
user 80, loss 0.24537632025545464, acc 0.3
user 20, loss 0.3307895376428497, acc 0.36
user 26, loss 0.31955345712762206, acc 0.48
user 18, loss 0.3394339824072085, acc 0.5
user 79, loss 0.20080736448602693, acc 0.5
user 53, loss 0.35141155731776963, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 62 global rounds:
Training Loss : 0.5737432032080129
Global model Benign Test Accuracy: 49.09% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 6.27 , Outputs: tensor([0.9392])


 | Global Training Round : 63 |

user 52, loss 0.21949455008580115, acc 0.48
user 73, loss 0.3483344209057396, acc 0.44
user 3, loss 0.2639506289488054, acc 0.46
user 87, loss 0.2640593678089499, acc 0.32
user 9, loss 0.40210903199564196, acc 0.3
user 40, loss 0.36679480030754347, acc 0.46
user 39, loss 0.3664143909706036, acc 0.38
user 70, loss 0.28714118561969376, acc 0.38
user 51, loss 0.28118129874870645, acc 0.28
user 31, loss 0.22171484799095195, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 63 global rounds:
Training Loss : 0.569431715098969
Global model Benign Test Accuracy: 49.09% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 5.58 , Outputs: tensor([0.9457])


 | Global Training Round : 64 |

user 96, loss 0.2607956310754525, acc 0.4
user 83, loss 0.25861450966447586, acc 0.4
user 5, loss 0.30902523071214094, acc 0.38
user 43, loss 0.2509028501150897, acc 0.46
user 14, loss 0.30310765420770625, acc 0.44
user 55, loss 0.3741234655035078, acc 0.42
user 87, loss 0.21959780091303402, acc 0.26
user 18, loss 0.27592133033584104, acc 0.42
user 39, loss 0.29513943490645034, acc 0.44
user 85, loss 0.3734692731883843, acc 0.52
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 64 global rounds:
Training Loss : 0.5650979338952693
Global model Benign Test Accuracy: 49.27% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 5.19 , Outputs: tensor([0.9494])


 | Global Training Round : 65 |

user 13, loss 0.22842163506997165, acc 0.32
user 95, loss 0.413979473685904, acc 0.42
user 27, loss 0.2661494993785163, acc 0.46
user 54, loss 0.2810753560831653, acc 0.32
user 18, loss 0.23783580796894963, acc 0.44
user 66, loss 0.2556979638202757, acc 0.58
user 28, loss 0.3093989301889087, acc 0.4
user 38, loss 0.3314972826486337, acc 0.44
user 71, loss 0.2076662989261968, acc 0.52
user 72, loss 0.25118122946674704, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 65 global rounds:
Training Loss : 0.5606855094926302
Global model Benign Test Accuracy: 48.60% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 8.38 , Outputs: tensor([0.9196])


 | Global Training Round : 66 |

user 0, loss 0.33603471125068607, acc 0.56
user 85, loss 0.31900472176668704, acc 0.46
user 66, loss 0.2325734183857276, acc 0.5
user 57, loss 0.30702673984109424, acc 0.3
user 48, loss 0.3608582540418138, acc 0.38
user 80, loss 0.2299923871297506, acc 0.34
user 43, loss 0.23092090728241604, acc 0.5
user 95, loss 0.3365367842259002, acc 0.34
user 35, loss 0.2878643869215739, acc 0.36
user 94, loss 0.4007319616148015, acc 0.38
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 66 global rounds:
Training Loss : 0.5567986749131365
Global model Benign Test Accuracy: 49.05% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 7.97 , Outputs: tensor([0.9234])


 | Global Training Round : 67 |

user 93, loss 0.3339803913232754, acc 0.46
user 96, loss 0.24490234023578522, acc 0.44
user 56, loss 0.29198094382969425, acc 0.44
user 27, loss 0.21768887734418968, acc 0.44
user 84, loss 0.27578179161573646, acc 0.34
user 37, loss 0.35565609432873313, acc 0.46
user 43, loss 0.2137490102635639, acc 0.48
user 82, loss 0.40980507616186523, acc 0.44
user 13, loss 0.2021387783053797, acc 0.38
user 41, loss 0.31024945110140834, acc 0.26
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 67 global rounds:
Training Loss : 0.552750833130119
Global model Benign Test Accuracy: 49.02% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 5.73 , Outputs: tensor([0.9443])


 | Global Training Round : 68 |

user 47, loss 0.344528696507332, acc 0.54
user 90, loss 0.2956105280524935, acc 0.42
user 27, loss 0.17918959871240078, acc 0.56
user 64, loss 0.3905693046114175, acc 0.48
user 86, loss 0.38199783706397283, acc 0.44
user 26, loss 0.2917806508537615, acc 0.4
user 31, loss 0.201033887529411, acc 0.44
user 59, loss 0.320704977317655, acc 0.5
user 95, loss 0.2724888882174855, acc 0.38
user 12, loss 0.29313981796804, acc 0.36 68%|██████▊   | 68/100 [21:35<11:11, 20.99s/it] 69%|██████▉   | 69/100 [21:55<10:39, 20.64s/it] 70%|███████   | 70/100 [22:15<10:08, 20.29s/it] 71%|███████   | 71/100 [22:33<09:27, 19.57s/it] 72%|███████▏  | 72/100 [22:52<09:07, 19.54s/it] 73%|███████▎  | 73/100 [23:09<08:24, 18.69s/it] 74%|███████▍  | 74/100 [23:28<08:08, 18.78s/it] 75%|███████▌  | 75/100 [23:47<07:54, 18.99s/it] 76%|███████▌  | 76/100 [24:07<07:41, 19.22s/it] 77%|███████▋  | 77/100 [24:27<07:25, 19.36s/it] 78%|███████▊  | 78/100 [24:46<07:07, 19.43s/it]
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 68 global rounds:
Training Loss : 0.5489913270353143
Global model Benign Test Accuracy: 49.13% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 13.11 , Outputs: tensor([0.8771])


 | Global Training Round : 69 |

user 11, loss 0.3087063106684946, acc 0.56
user 82, loss 0.3166090356749192, acc 0.42
user 78, loss 0.27442784899525585, acc 0.4
user 98, loss 0.3156909759630798, acc 0.46
user 57, loss 0.2518819419966894, acc 0.36
user 35, loss 0.2778314527496696, acc 0.36
user 26, loss 0.2379360068998358, acc 0.46
user 37, loss 0.2970224151670119, acc 0.48
user 39, loss 0.25573499160469504, acc 0.38
user 81, loss 0.4190900167287328, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 69 global rounds:
Training Loss : 0.5453174396818291
Global model Benign Test Accuracy: 49.59% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 8.98 , Outputs: tensor([0.9141])


 | Global Training Round : 70 |

user 15, loss 0.34125580811567485, acc 0.4
user 26, loss 0.21326254657440585, acc 0.44
user 62, loss 0.30699073480558586, acc 0.56
user 33, loss 0.27883707419154236, acc 0.44
user 87, loss 0.22677418618230152, acc 0.28
user 19, loss 0.2406682770344196, acc 0.42
user 20, loss 0.31337568773436947, acc 0.4
user 41, loss 0.28468533315055533, acc 0.26
user 13, loss 0.18722274472049322, acc 0.38
user 73, loss 0.31650520891038475, acc 0.4
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 70 global rounds:
Training Loss : 0.5413980156884026
Global model Benign Test Accuracy: 49.28% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 12.53 , Outputs: tensor([0.8822])


 | Global Training Round : 71 |

user 40, loss 0.3284470397993573, acc 0.4
user 48, loss 0.2839504140985082, acc 0.44
user 14, loss 0.2772902476628951, acc 0.42
user 80, loss 0.2180255541515362, acc 0.36
user 25, loss 0.3362035235125222, acc 0.46
user 4, loss 0.3642722496681381, acc 0.44
Malcious user 7 is selected!
user 7, loss 0.012575111398109583, acc 0.4, mal loss 2.5987286790041253e-05, mal acc 1.0
user 44, loss 0.33834840473544314, acc 0.42
user 83, loss 0.26687420301066594, acc 0.42
user 94, loss 0.3665936798372423, acc 0.42
[0, 0, 0, 0, 1, 1, 5, 1, 1, 1]
 
Avg Training Stats after 71 global rounds:
Training Loss : 0.5377059033940228
Global model Benign Test Accuracy: 49.35% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.00 , Outputs: tensor([1.0000])


 | Global Training Round : 72 |

user 60, loss 0.4366525555924454, acc 0.46
user 41, loss 0.3276626823955303, acc 0.24
user 42, loss 0.41407077738418596, acc 0.4
user 97, loss 0.3721461612128768, acc 0.54
user 26, loss 0.23483068402019852, acc 0.38
user 61, loss 0.45291750957432664, acc 0.38
user 37, loss 0.3718030978002934, acc 0.46
user 33, loss 0.3145469356425747, acc 0.46
user 38, loss 0.3979562842598534, acc 0.4
user 2, loss 0.46907513585261773, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 72 global rounds:
Training Loss : 0.5355039628242932
Global model Benign Test Accuracy: 48.55% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.14 , Outputs: tensor([0.9986])


 | Global Training Round : 73 |

user 10, loss 0.37484911950741656, acc 0.46
user 37, loss 0.24271173269560675, acc 0.5
Malcious user 7 is selected!
user 7, loss 0.0007176658051321283, acc 0.44, mal loss 0.00032050241134129465, mal acc 1.0
user 77, loss 0.43561406014370735, acc 0.52
user 2, loss 0.3174674086779123, acc 0.46
user 18, loss 0.3301118304650299, acc 0.44
user 20, loss 0.34755501381412623, acc 0.4
user 31, loss 0.2283001990645425, acc 0.4
user 67, loss 0.30789832615038903, acc 0.44
user 44, loss 0.35531782161036973, acc 0.42
[0, 0, 5, 0, 0, 1, 1, 1, 1, 1]
 
Avg Training Stats after 73 global rounds:
Training Loss : 0.5321964334403088
Global model Benign Test Accuracy: 48.81% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.00 , Outputs: tensor([1.0000])


 | Global Training Round : 74 |

user 33, loss 0.33628357723842783, acc 0.4
user 80, loss 0.4039282184816694, acc 0.3
user 42, loss 0.5119401136481609, acc 0.34
user 36, loss 0.6089006611227523, acc 0.46
user 10, loss 0.4451038639192847, acc 0.42
user 13, loss 0.2892033114544392, acc 0.42
user 77, loss 0.6284211499613593, acc 0.44
user 94, loss 0.5332934596572886, acc 0.42
user 20, loss 0.37395143959067345, acc 0.42
user 70, loss 0.47884376566456927, acc 0.4
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 74 global rounds:
Training Loss : 0.531234143205627
Global model Benign Test Accuracy: 47.80% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.12 , Outputs: tensor([0.9988])


 | Global Training Round : 75 |

user 92, loss 0.48030407957994603, acc 0.54
user 64, loss 0.5438362970451999, acc 0.52
user 38, loss 0.29748265117246775, acc 0.46
user 22, loss 0.4422934972342046, acc 0.48
user 42, loss 0.29870443008650915, acc 0.34
user 57, loss 0.2887122741999338, acc 0.32
user 71, loss 0.2603594612519374, acc 0.48
user 44, loss 0.3263143842371937, acc 0.42
user 98, loss 0.3554984901900025, acc 0.48
user 80, loss 0.2965456708915008, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 75 global rounds:
Training Loss : 0.5289377562774038
Global model Benign Test Accuracy: 47.79% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.02 , Outputs: tensor([0.9998])


 | Global Training Round : 76 |

user 9, loss 0.481112914276091, acc 0.32
user 54, loss 0.33554820303303134, acc 0.32
user 1, loss 0.4369148039395804, acc 0.38
user 15, loss 0.37412195395721937, acc 0.4
user 81, loss 0.3942547560553066, acc 0.46
user 14, loss 0.3430519377026212, acc 0.4
user 95, loss 0.3735208426724421, acc 0.28
user 55, loss 0.47088739268161595, acc 0.48
user 6, loss 0.4701625467202393, acc 0.38
user 86, loss 0.4344225369446213, acc 0.52
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 76 global rounds:
Training Loss : 0.5273912040737311
Global model Benign Test Accuracy: 48.16% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.38 , Outputs: tensor([0.9962])


 | Global Training Round : 77 |

user 65, loss 0.3942825854540569, acc 0.42
user 8, loss 0.4460889633108308, acc 0.44
user 20, loss 0.27094352077459916, acc 0.28
user 52, loss 0.37371096395465436, acc 0.38
user 66, loss 0.28311871127218186, acc 0.52
user 4, loss 0.41120912345475513, acc 0.36
user 81, loss 0.3437723446884774, acc 0.46
user 39, loss 0.33899608813146187, acc 0.36
user 33, loss 0.2088516162615269, acc 0.4
user 88, loss 0.39880977796870865, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 77 global rounds:
Training Loss : 0.5250481802484505
Global model Benign Test Accuracy: 48.18% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.19 , Outputs: tensor([0.9981])


 | Global Training Round : 78 |

user 26, loss 0.2179311339178093, acc 0.38
user 81, loss 0.2699635327506985, acc 0.42
user 36, loss 0.441208247034083, acc 0.42
user 78, loss 0.33380400173991803, acc 0.4
user 60, loss 0.32794868553217377, acc 0.4
user 63, loss 0.2927045852701849, acc 0.38
user 8, loss 0.39727167898774496, acc 0.46
user 58, loss 0.5853365274053068, acc 0.44
user 86, loss 0.33940375580976256, acc 0.5
user 44, loss 0.2502587856680475, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 78 global rounds:
Training Loss : 0.5227473458018238
Global model Benign Test Accuracy: 48.07% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.80 , Outputs: tensor([0.9920])


 | Global Training Round : 79 |

user 31, loss 0.25057105744053837, acc 0.4
user 4, loss 0.31906173378913083, acc 0.4
user 49, loss 0.34502814312480035, acc 0.36
user 62, loss 0.3089220764455967, acc 0.46
user 74, loss 0.43607687800657, acc 0.36
user 59, loss 0.36217767163223474, acc 0.52
user 86, loss 0.257970708336361, acc 0.44
user 25, loss 0.38858761885858256, acc 0.52
user 18, loss 0.2867336858299677, acc 0.42
user 68, loss 0.3836866925451613, acc 0.56
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 79 global rounds:
Training Loss : 0.5203566404954829
Global model Benign Test Accuracy: 48.18% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.94 , Outputs: tensor([0.9906])
 79%|███████▉  | 79/100 [25:06<06:50, 19.54s/it] 80%|████████  | 80/100 [25:26<06:30, 19.53s/it] 81%|████████  | 81/100 [25:45<06:12, 19.58s/it] 82%|████████▏ | 82/100 [26:06<05:56, 19.80s/it] 83%|████████▎ | 83/100 [26:27<05:43, 20.21s/it] 84%|████████▍ | 84/100 [26:46<05:20, 20.03s/it] 85%|████████▌ | 85/100 [27:04<04:49, 19.28s/it] 86%|████████▌ | 86/100 [27:23<04:30, 19.32s/it] 87%|████████▋ | 87/100 [27:45<04:18, 19.92s/it] 88%|████████▊ | 88/100 [28:03<03:51, 19.33s/it] 89%|████████▉ | 89/100 [28:22<03:33, 19.37s/it] 90%|█████████ | 90/100 [28:41<03:13, 19.35s/it]

 | Global Training Round : 80 |

user 25, loss 0.28680131269517, acc 0.46
user 74, loss 0.3602416841132799, acc 0.32
user 80, loss 0.25625775272303153, acc 0.44
user 1, loss 0.3655840598781651, acc 0.38
user 54, loss 0.30017631519833227, acc 0.32
user 33, loss 0.19363273332572137, acc 0.4
user 89, loss 0.3696923821009114, acc 0.56
user 67, loss 0.3127418218937236, acc 0.5
user 31, loss 0.18368137577097512, acc 0.32
user 8, loss 0.28127691636080276, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 80 global rounds:
Training Loss : 0.5174897904318646
Global model Benign Test Accuracy: 47.59% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.97 , Outputs: tensor([0.9904])


 | Global Training Round : 81 |

user 63, loss 0.21681858956813813, acc 0.26
user 71, loss 0.22743092006276128, acc 0.4
user 86, loss 0.24766199758159932, acc 0.44
user 60, loss 0.2934817060478963, acc 0.48
user 38, loss 0.3101950913510517, acc 0.42
user 73, loss 0.3513150405531632, acc 0.54
user 69, loss 0.28598030915600237, acc 0.54
user 0, loss 0.359248502180708, acc 0.5
user 56, loss 0.29597140734098504, acc 0.5
user 64, loss 0.4085493894832325, acc 0.52
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 81 global rounds:
Training Loss : 0.5148005991343423
Global model Benign Test Accuracy: 48.21% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.09 , Outputs: tensor([0.9991])


 | Global Training Round : 82 |

user 65, loss 0.2886141109271557, acc 0.54
user 15, loss 0.3511325977064553, acc 0.38
user 40, loss 0.36049790182805735, acc 0.46
user 86, loss 0.18839459755086865, acc 0.5
user 75, loss 0.44453005445015153, acc 0.48
user 44, loss 0.271702389184702, acc 0.4
user 52, loss 0.24699960032798116, acc 0.44
user 54, loss 0.20889727081517767, acc 0.34
user 27, loss 0.2380487666945555, acc 0.5
user 60, loss 0.230106904389395, acc 0.5
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 82 global rounds:
Training Loss : 0.5119724506008436
Global model Benign Test Accuracy: 47.90% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.07 , Outputs: tensor([0.9993])


 | Global Training Round : 83 |

user 78, loss 0.2515792555322697, acc 0.4
user 57, loss 0.23344084500262402, acc 0.46
user 94, loss 0.3171146612931624, acc 0.42
user 9, loss 0.3384146273238003, acc 0.3
user 18, loss 0.23519743232605833, acc 0.42
user 90, loss 0.343148123322826, acc 0.44
user 41, loss 0.26729881014864076, acc 0.32
user 72, loss 0.3265385557427362, acc 0.46
user 69, loss 0.23696725466048515, acc 0.48
user 99, loss 0.31663769033766587, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 83 global rounds:
Training Loss : 0.5092575262028699
Global model Benign Test Accuracy: 48.35% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.09 , Outputs: tensor([0.9991])


 | Global Training Round : 84 |

user 50, loss 0.3765324837240041, acc 0.4
user 48, loss 0.3562111863182509, acc 0.42
user 19, loss 0.2797360123018734, acc 0.32
user 3, loss 0.33078909062729517, acc 0.4
user 94, loss 0.2779850577455362, acc 0.34
user 13, loss 0.22610630108421903, acc 0.32
user 61, loss 0.36230027823126876, acc 0.4
user 96, loss 0.29603163668303745, acc 0.42
user 18, loss 0.1763063543273165, acc 0.4
user 76, loss 0.42563092824770143, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 84 global rounds:
Training Loss : 0.5068944953305625
Global model Benign Test Accuracy: 48.47% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.30 , Outputs: tensor([0.9970])


 | Global Training Round : 85 |

user 73, loss 0.29739144289065733, acc 0.48
user 27, loss 0.1952073992836813, acc 0.46
user 17, loss 0.3953594992021681, acc 0.44
user 65, loss 0.2344087045146444, acc 0.5
user 44, loss 0.19362867054718663, acc 0.52
user 81, loss 0.26857875586632873, acc 0.36
user 15, loss 0.27466604920788085, acc 0.36
user 83, loss 0.3053502089391077, acc 0.44
Malcious user 7 is selected!
user 7, loss 0.0009098277485463768, acc 0.46, mal loss 0.0002562671434134245, mal acc 1.0
user 14, loss 0.3107648583491392, acc 0.38
[0, 0, 0, 0, 1, 1, 1, 1, 5, 1]
 
Avg Training Stats after 85 global rounds:
Training Loss : 0.5038442841108492
Global model Benign Test Accuracy: 48.35% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.01 , Outputs: tensor([0.9999])


 | Global Training Round : 86 |

user 90, loss 0.424389728011447, acc 0.38
user 13, loss 0.26409159576443925, acc 0.28
user 19, loss 0.32747209638844643, acc 0.28
user 29, loss 0.547663247071323, acc 0.34
user 21, loss 0.5749815683535417, acc 0.56
user 22, loss 0.45481051687267604, acc 0.38
user 76, loss 0.4506204475669075, acc 0.36
user 51, loss 0.5440455754788127, acc 0.28
user 28, loss 0.5428576823230833, acc 0.54
user 80, loss 0.32663798753128515, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 86 global rounds:
Training Loss : 0.5031688510925393
Global model Benign Test Accuracy: 47.07% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.02 , Outputs: tensor([0.9998])


 | Global Training Round : 87 |

user 20, loss 0.30484982007707007, acc 0.44
user 76, loss 0.2826551074311283, acc 0.36
user 51, loss 0.29631168970096045, acc 0.36
user 69, loss 0.24659286600646743, acc 0.44
user 29, loss 0.3511723646598694, acc 0.34
user 11, loss 0.44366540285060185, acc 0.54
user 92, loss 0.42439706791046755, acc 0.5
user 81, loss 0.26376079939313063, acc 0.48
user 40, loss 0.3238054376812943, acc 0.52
user 26, loss 0.2342042452442547, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 87 global rounds:
Training Loss : 0.5010306054488953
Global model Benign Test Accuracy: 47.53% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.05 , Outputs: tensor([0.9995])


 | Global Training Round : 88 |

user 74, loss 0.4224931932361504, acc 0.3
user 18, loss 0.21659929971359815, acc 0.36
user 72, loss 0.3307012984302128, acc 0.4
user 50, loss 0.3781053159432485, acc 0.38
user 14, loss 0.29527963229993476, acc 0.48
user 29, loss 0.29609967697120737, acc 0.42
Malcious user 7 is selected!
user 7, loss 0.0003247397631639615, acc 0.46, mal loss 0.00017772526189219207, mal acc 1.0
user 54, loss 0.23675446820878276, acc 0.28
user 24, loss 0.47045360213858667, acc 0.38
user 81, loss 0.1936199062250671, acc 0.38
[0, 0, 0, 0, 1, 1, 5, 1, 1, 1]
 
Avg Training Stats after 88 global rounds:
Training Loss : 0.4985648384925785
Global model Benign Test Accuracy: 47.51% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.01 , Outputs: tensor([0.9999])


 | Global Training Round : 89 |

user 95, loss 0.6736505098050839, acc 0.3
user 61, loss 0.5484776886858163, acc 0.32
user 70, loss 0.5800398073540419, acc 0.36
user 60, loss 0.44944856504720515, acc 0.4
user 5, loss 0.5944965148816117, acc 0.42
user 14, loss 0.41864050370848405, acc 0.38
user 8, loss 0.5465715460554201, acc 0.46
user 72, loss 0.5170741265335892, acc 0.44
user 22, loss 0.45795349905180044, acc 0.46
user 85, loss 0.736080772090354, acc 0.28
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 89 global rounds:
Training Loss : 0.4991679678726769
Global model Benign Test Accuracy: 46.88% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 89.84 , Outputs: tensor([0.4072])


 | Global Training Round : 90 |

user 91, loss 0.6151280186080839, acc 0.4
user 78, loss 0.3741478149821341, acc 0.36
user 96, loss 0.3596290878854506, acc 0.4
user 36, loss 0.6695789717527805, acc 0.3
user 62, loss 0.44753009024396295, acc 0.5
user 48, loss 0.4015678466343524, acc 0.34
user 42, loss 0.3838969567062668, acc 0.44
user 56, loss 0.4155648438711796, acc 0.48
user 44, loss 0.32964049431025394, acc 0.42
user 34, loss 0.5344942218236974, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 90 global rounds:
Training Loss : 0.4986562997261118
Global model Benign Test Accuracy: 47.25% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 3.00 , Outputs: tensor([0.9704])


 | Global Training Round : 91 |

user 4, loss 0.4579198772711243, acc 0.34
user 51, loss 0.39391959182758, acc 0.28
user 93, loss 0.47127929761190906, acc 0.44
user 38, loss 0.3816304006664723, acc 0.46
user 81, loss 0.2718645155128616, acc 0.4 91%|█████████ | 91/100 [29:00<02:53, 19.24s/it] 92%|█████████▏| 92/100 [29:19<02:33, 19.20s/it] 93%|█████████▎| 93/100 [29:37<02:10, 18.66s/it] 94%|█████████▍| 94/100 [29:56<01:51, 18.65s/it] 95%|█████████▌| 95/100 [30:14<01:33, 18.62s/it] 96%|█████████▌| 96/100 [30:31<01:12, 18.04s/it] 97%|█████████▋| 97/100 [30:45<00:50, 16.94s/it] 98%|█████████▊| 98/100 [31:02<00:33, 16.90s/it] 99%|█████████▉| 99/100 [31:18<00:16, 16.70s/it]100%|██████████| 100/100 [31:34<00:00, 16.42s/it]100%|██████████| 100/100 [31:34<00:00, 18.94s/it]

user 10, loss 0.496024886060768, acc 0.36
user 63, loss 0.3267962227006501, acc 0.36
user 23, loss 0.6711241688572045, acc 0.46
user 33, loss 0.315429852204179, acc 0.36
user 52, loss 0.37726964188539563, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 91 global rounds:
Training Loss : 0.4977515694594492
Global model Benign Test Accuracy: 47.23% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.07 , Outputs: tensor([0.9993])


 | Global Training Round : 92 |

user 88, loss 0.4218923256007837, acc 0.44
user 64, loss 0.4367438131306699, acc 0.5
user 51, loss 0.28076413615213824, acc 0.26
user 92, loss 0.40475215404643683, acc 0.5
user 96, loss 0.3047941362521306, acc 0.4
user 0, loss 0.4880390855410952, acc 0.52
user 32, loss 0.4438054590713, acc 0.36
user 12, loss 0.4818955332605401, acc 0.4
user 46, loss 0.5364772513938079, acc 0.36
user 38, loss 0.30198596620772156, acc 0.42
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 92 global rounds:
Training Loss : 0.49679899790082116
Global model Benign Test Accuracy: 47.64% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.07 , Outputs: tensor([0.9993])


 | Global Training Round : 93 |

user 54, loss 0.30029433595649613, acc 0.3
user 48, loss 0.2943269626469191, acc 0.3
user 0, loss 0.3587054037720373, acc 0.36
user 96, loss 0.23480359332064835, acc 0.4
user 5, loss 0.36411945478990676, acc 0.4
user 11, loss 0.3349706707178848, acc 0.52
Malcious user 7 is selected!
user 7, loss 0.00031574392050970346, acc 0.5, mal loss 0.00012659224739763886, mal acc 1.0
user 13, loss 0.22045889585848272, acc 0.34
user 38, loss 0.2202814730971295, acc 0.42
user 12, loss 0.3672103297810827, acc 0.42
[0, 0, 0, 0, 1, 1, 5, 1, 1, 1]
 
Avg Training Stats after 93 global rounds:
Training Loss : 0.4943554461641038
Global model Benign Test Accuracy: 47.52% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.02 , Outputs: tensor([0.9998])


 | Global Training Round : 94 |

user 1, loss 0.7113113032893307, acc 0.38
user 65, loss 0.6557282589803799, acc 0.48
user 68, loss 0.8087530444876757, acc 0.5
user 37, loss 0.8269764478108845, acc 0.44
user 25, loss 0.609936468110318, acc 0.48
user 71, loss 0.4554387657238113, acc 0.42
user 83, loss 0.6494115086147213, acc 0.44
user 32, loss 0.5560729102150073, acc 0.44
user 80, loss 0.5608035660773021, acc 0.5
user 10, loss 0.6560443724883227, acc 0.46
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 94 global rounds:
Training Loss : 0.49600110806214287
Global model Benign Test Accuracy: 46.40% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 374.23 , Outputs: tensor([0.0237])


 | Global Training Round : 95 |

user 6, loss 0.6225290111824869, acc 0.42
user 13, loss 0.26223689148842827, acc 0.36
user 47, loss 0.672710689593805, acc 0.48
user 41, loss 0.3838110135678289, acc 0.26
user 69, loss 0.31823905630532745, acc 0.46
user 76, loss 0.4398003252685886, acc 0.48
user 64, loss 0.49639138610742517, acc 0.46
user 57, loss 0.4367370790797577, acc 0.42
user 58, loss 0.7564237561565824, acc 0.38
user 38, loss 0.2667439559602644, acc 0.36
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 95 global rounds:
Training Loss : 0.49568069972960505
Global model Benign Test Accuracy: 47.05% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.14 , Outputs: tensor([0.9986])


 | Global Training Round : 96 |

user 87, loss 0.4176587881543673, acc 0.3
user 37, loss 0.52761620146317, acc 0.44
user 20, loss 0.37875618061640126, acc 0.42
user 94, loss 0.4320133686484769, acc 0.38
user 31, loss 0.3871191813229961, acc 0.36
user 15, loss 0.45719424758426613, acc 0.42
Malcious user 7 is selected!
user 7, loss 0.0003482378589978907, acc 0.46, mal loss 7.176141662057489e-05, mal acc 1.0
user 77, loss 0.681944272830733, acc 0.52
user 82, loss 0.6658818718302063, acc 0.48
user 81, loss 0.24716500585498585, acc 0.42
[0, 0, 0, 0, 1, 1, 5, 1, 1, 1]
 
Avg Training Stats after 96 global rounds:
Training Loss : 0.49488787718675975
Global model Benign Test Accuracy: 46.60% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 0.00 , Outputs: tensor([1.0000])


 | Global Training Round : 97 |

user 25, loss 0.7003479734149731, acc 0.34
user 81, loss 0.3887989571917797, acc 0.38
user 66, loss 0.9438902820484874, acc 0.46
user 20, loss 0.8744688346143812, acc 0.26
user 22, loss 0.7423169915997277, acc 0.44
user 74, loss 0.8907910954221734, acc 0.28
user 40, loss 0.994736858845281, acc 0.42
user 1, loss 0.8445750783523545, acc 0.3
Malcious user 7 is selected!
user 7, loss 1.2934123787999852e-05, acc 0.52, mal loss 1.1205610462639015e-05, mal acc 1.0
user 23, loss 1.023111924873665, acc 0.34
[0, 0, 0, 0, 1, 1, 1, 1, 5, 1]
 
Avg Training Stats after 97 global rounds:
Training Loss : 0.4974179515770886
Global model Benign Test Accuracy: 45.76% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 874.49 , Outputs: tensor([0.0002])


 | Global Training Round : 98 |

user 66, loss 1.187390963966027, acc 0.44
user 24, loss 1.5668996783718465, acc 0.32
user 22, loss 0.8007093206349236, acc 0.42
user 72, loss 1.124143185415305, acc 0.44
user 96, loss 0.9147841800306924, acc 0.34
user 20, loss 1.5294543779455123, acc 0.34
user 76, loss 1.1525602671841624, acc 0.32
user 58, loss 1.4649643079377712, acc 0.36
user 42, loss 1.5629221224039793, acc 0.28
user 56, loss 1.168979062438011, acc 0.48
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 98 global rounds:
Training Loss : 0.5050696127511267
Global model Benign Test Accuracy: 39.15% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 574.51 , Outputs: tensor([0.0032])


 | Global Training Round : 99 |

user 19, loss 0.7379954880214062, acc 0.38
user 34, loss 1.0019770676409823, acc 0.24
user 44, loss 0.7098543003907798, acc 0.32
user 12, loss 0.786410813970724, acc 0.46
user 66, loss 0.6902257446038129, acc 0.36
user 94, loss 0.8230214158729359, acc 0.34
user 43, loss 0.8829093478532741, acc 0.34
user 48, loss 0.778494778830791, acc 0.34
user 36, loss 0.9652005894389003, acc 0.38
user 33, loss 0.6116933974224229, acc 0.28
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 99 global rounds:
Training Loss : 0.5080363671112629
Global model Benign Test Accuracy: 43.37% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 936.00 , Outputs: tensor([8.6099e-05])


 | Global Training Round : 100 |

user 22, loss 0.4789720532034698, acc 0.44
user 27, loss 0.764937324388302, acc 0.5
user 48, loss 0.6277894165471661, acc 0.3
user 87, loss 0.6689779520587763, acc 0.24
user 66, loss 0.5807322433227091, acc 0.42
user 10, loss 0.6299989866133547, acc 0.48
user 0, loss 0.8239509614091366, acc 0.48
user 36, loss 0.6959411206725054, acc 0.4
user 31, loss 0.5781399856002827, acc 0.3
user 89, loss 0.8088649310357869, acc 0.44
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
 
Avg Training Stats after 100 global rounds:
Training Loss : 0.5096143084150018
Global model Benign Test Accuracy: 44.36% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 350.83 , Outputs: tensor([0.0299])

 
 Results after 100 global rounds of training:
|---- Test Accuracy: 44.36%
Traceback (most recent call last):
  File "fedavg.py", line 149, in <module>
    with open(file_name, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../save/objects/cifar_cnn_100_C[0.1]_iid[1]_E[10]_B[10].pkl'
