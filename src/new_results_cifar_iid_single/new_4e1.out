nohup: ignoring input
  0%|          | 0/100 [00:00<?, ?it/s]/home/js905/code/FL-WBC/src/update.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(image), torch.tensor(label)
/home/js905/anaconda2/envs/pytorch0.4/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/home/js905/code/FL-WBC/src/update.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(image), torch.tensor(label_mal), torch.tensor(label)
  1%|          | 1/100 [00:29<48:35, 29.45s/it]  2%|▏         | 2/100 [00:55<46:37, 28.55s/it]  3%|▎         | 3/100 [01:24<46:24, 28.71s/it]  4%|▍         | 4/100 [01:51<44:47, 28.00s/it]  5%|▌         | 5/100 [02:20<44:50, 28.32s/it]  6%|▌         | 6/100 [02:49<44:41, 28.53s/it]  7%|▋         | 7/100 [03:18<44:25, 28.66s/it]  8%|▊         | 8/100 [03:44<42:49, 27.93s/it]  9%|▉         | 9/100 [04:13<42:50, 28.25s/it] 10%|█         | 10/100 [04:42<42:41, 28.46s/it]
Experimental details:
    Model     : cnn
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 100

    Federated parameters:
    IID
    Fraction of users  : 0.1
    Local Batch size   : 10
    Local Epochs       : 10

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
[3545]
malcious dataset true labels: [4], malicious labels: [8]

 | Global Training Round : 1 |

user 21, loss 2.3393785226345054, acc 0.14
user 75, loss 2.3203252187371257, acc 0.16
user 41, loss 2.3356641328334806, acc 0.06
user 91, loss 2.3150027740001677, acc 0.18
user 86, loss 2.3279492253065106, acc 0.1
user 77, loss 2.3266786897182468, acc 0.22
user 54, loss 2.321154910027981, acc 0.18
user 57, loss 2.3051414462924003, acc 0.12
user 1, loss 2.267843844294548, acc 0.16
user 32, loss 2.290682436227798, acc 0.16
 
Avg Training Stats after 1 global rounds:
Training Loss : 2.3149821200072767
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 234.53 , Outputs: tensor([0.0958])


 | Global Training Round : 2 |

user 61, loss 2.303627870082855, acc 0.08
user 51, loss 2.303237335085869, acc 0.1
user 39, loss 2.29443571805954, acc 0.1
user 75, loss 2.3003104263544083, acc 0.14
user 74, loss 2.2964386004209514, acc 0.1
user 93, loss 2.2983253830671306, acc 0.16
user 81, loss 2.2974423491954803, acc 0.06
user 23, loss 2.2960244917869566, acc 0.12
user 92, loss 2.301700533032417, acc 0.08
Malcious user 7 is selected!
user 7, loss 2.2786179065704344, acc 0.12, mal loss 2.1842010021209717, mal acc 1.0
 
Avg Training Stats after 2 global rounds:
Training Loss : 2.3059990906864405
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 225.27 , Outputs: tensor([0.1051])


 | Global Training Round : 3 |

user 98, loss 2.2915537220239637, acc 0.04
user 94, loss 2.2986438995599747, acc 0.06
user 73, loss 2.2953991967439658, acc 0.1
user 2, loss 2.296466499567032, acc 0.1
user 6, loss 2.3013080102205277, acc 0.1
user 36, loss 2.2964542526006695, acc 0.16
user 70, loss 2.300070648789406, acc 0.04
user 82, loss 2.2963934296369546, acc 0.1
user 34, loss 2.2965916401147837, acc 0.12
user 19, loss 2.3005573379993436, acc 0.06
 
Avg Training Stats after 3 global rounds:
Training Loss : 2.3031140150328477
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 226.11 , Outputs: tensor([0.1042])


 | Global Training Round : 4 |

user 83, loss 2.298675417900085, acc 0.12
user 51, loss 2.301198661327362, acc 0.1
user 65, loss 2.30018499314785, acc 0.08
user 97, loss 2.3001907795667647, acc 0.14
user 29, loss 2.2964721173048015, acc 0.2
user 44, loss 2.2960530745983125, acc 0.08
user 77, loss 2.296443693041801, acc 0.18
Malcious user 7 is selected!
user 7, loss 2.19573917388916, acc 0.12, mal loss 2.103240728378296, mal acc 1.0
user 98, loss 2.290053535699845, acc 0.12
user 80, loss 2.3020847016572956, acc 0.06
 
Avg Training Stats after 4 global rounds:
Training Loss : 2.2992629149779678
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 216.83 , Outputs: tensor([0.1144])


 | Global Training Round : 5 |

user 48, loss 2.2992113173007964, acc 0.06
user 21, loss 2.303829795718193, acc 0.06
user 63, loss 2.2952102309465405, acc 0.16
user 78, loss 2.297076735496521, acc 0.08
user 75, loss 2.30176159799099, acc 0.14
user 69, loss 2.2970087808370594, acc 0.06
user 29, loss 2.296903256177902, acc 0.2
user 24, loss 2.298703554868698, acc 0.1
user 35, loss 2.2995649546384813, acc 0.12
user 64, loss 2.3004466855525973, acc 0.16
 
Avg Training Stats after 5 global rounds:
Training Loss : 2.2992046701729296
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 229.05 , Outputs: tensor([0.1012])


 | Global Training Round : 6 |

user 50, loss 2.301124592423439, acc 0.16
user 13, loss 2.301494251489639, acc 0.04
user 29, loss 2.2943957698345185, acc 0.2
user 67, loss 2.2958537453413013, acc 0.16
user 97, loss 2.299797131419182, acc 0.14
user 44, loss 2.295063068270683, acc 0.08
user 57, loss 2.2983880621194834, acc 0.06
user 73, loss 2.298279778957367, acc 0.1
user 62, loss 2.2951276242733, acc 0.02
user 10, loss 2.3016232019662857, acc 0.08
 
Avg Training Stats after 6 global rounds:
Training Loss : 2.2990230122456947
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.57 , Outputs: tensor([0.1027])


 | Global Training Round : 7 |

user 38, loss 2.3020517826080322, acc 0.08
user 24, loss 2.29653569817543, acc 0.1
user 69, loss 2.294571583271026, acc 0.06
user 11, loss 2.3028411394357677, acc 0.12
user 81, loss 2.2973298144340513, acc 0.16
user 25, loss 2.297693366408348, acc 0.04
user 34, loss 2.295520953536033, acc 0.12
user 21, loss 2.30243311226368, acc 0.06
user 35, loss 2.2978208261728286, acc 0.12
user 37, loss 2.3002873808145523, acc 0.06
 
Avg Training Stats after 7 global rounds:
Training Loss : 2.298978091312306
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.74 , Outputs: tensor([0.0995])


 | Global Training Round : 8 |

user 31, loss 2.300655460357666, acc 0.1
Malcious user 7 is selected!
user 7, loss 2.2413758039474487, acc 0.12, mal loss 2.147836923599243, mal acc 1.0
user 92, loss 2.300295694470406, acc 0.08
user 73, loss 2.298440080285072, acc 0.1
user 24, loss 2.2944008988142013, acc 0.1
user 66, loss 2.293199679255486, acc 0.06
user 64, loss 2.3016006940603257, acc 0.06
user 43, loss 2.2967989438772203, acc 0.08
user 49, loss 2.2968137699365614, acc 0.06
user 5, loss 2.295247502923012, acc 0.06
 
Avg Training Stats after 8 global rounds:
Training Loss : 2.29809118649736
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 221.25 , Outputs: tensor([0.1094])


 | Global Training Round : 9 |

user 89, loss 2.2958305883407593, acc 0.08
user 63, loss 2.293633115887642, acc 0.16
user 73, loss 2.2977655386924747, acc 0.1
user 34, loss 2.2966317069530486, acc 0.12
user 60, loss 2.294446839094162, acc 0.06
user 17, loss 2.3010877686738964, acc 0.06
user 87, loss 2.3025678068399427, acc 0.06
user 8, loss 2.2994568473100663, acc 0.08
user 83, loss 2.29789078772068, acc 0.12
user 46, loss 2.3009059256315227, acc 0.06
 
Avg Training Stats after 9 global rounds:
Training Loss : 2.2980834649436996
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.49 , Outputs: tensor([0.1059])


 | Global Training Round : 10 |

user 17, loss 2.3004764509201046, acc 0.06
user 1, loss 2.302792757749557, acc 0.14
user 3, loss 2.295569834113121, acc 0.14
user 93, loss 2.2962223559618, acc 0.16
user 45, loss 2.301189380884171, acc 0.1
user 99, loss 2.300172761678696, acc 0.08
user 49, loss 2.296163092255592, acc 0.06
user 27, loss 2.2941171127557753, acc 0.08
user 38, loss 2.3015664917230603, acc 0.08
user 41, loss 2.301482447385788, acc 0.1
 
Avg Training Stats after 10 global rounds:
Training Loss : 2.298172645303606
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.95 , Outputs: tensor([0.1055])


 | Global Training Round : 11 |

user 22, loss 2.2961931550502777, acc 0.1
user 53, loss 2.299306607246399, acc 0.1
user 30, loss 2.2991174614429473, acc 0.14
user 41, loss 2.30041290640831, acc 0.02
user 50, loss 2.3022019302845, acc 0.16
user 85, loss 2.2989822673797606, acc 0.14
user 52, loss 2.298258677124977, acc 0.14
user 36, loss 2.29457377076149, acc 0.16
user 51, loss 2.3001457953453066, acc 0.1
user 74, loss 2.2967298263311386, acc 0.1
 
Avg Training Stats after 11 global rounds:
Training Loss : 2.298210790252143 11%|█         | 11/100 [05:11<42:26, 28.61s/it] 12%|█▏        | 12/100 [05:40<42:07, 28.72s/it] 13%|█▎        | 13/100 [06:09<41:44, 28.78s/it] 14%|█▍        | 14/100 [06:38<41:19, 28.83s/it] 15%|█▌        | 15/100 [07:07<40:53, 28.86s/it] 16%|█▌        | 16/100 [07:36<40:26, 28.89s/it] 17%|█▋        | 17/100 [08:05<39:59, 28.91s/it] 18%|█▊        | 18/100 [08:31<38:24, 28.10s/it] 19%|█▉        | 19/100 [09:00<38:17, 28.36s/it] 20%|██        | 20/100 [09:29<38:03, 28.55s/it] 21%|██        | 21/100 [09:58<37:45, 28.68s/it] 22%|██▏       | 22/100 [10:27<37:27, 28.81s/it]
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.79 , Outputs: tensor([0.1046])


 | Global Training Round : 12 |

user 60, loss 2.296305818557739, acc 0.06
user 96, loss 2.2974022585153575, acc 0.12
user 25, loss 2.2971022439002993, acc 0.04
user 70, loss 2.298734833598137, acc 0.04
user 32, loss 2.2950540828704833, acc 0.06
user 73, loss 2.2968790966272357, acc 0.1
user 20, loss 2.3005031317472455, acc 0.04
user 91, loss 2.2994853812456135, acc 0.08
user 84, loss 2.301121265888214, acc 0.04
user 40, loss 2.2964286148548125, acc 0.1
 
Avg Training Stats after 12 global rounds:
Training Loss : 2.298185030462841
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.36 , Outputs: tensor([0.1040])


 | Global Training Round : 13 |

user 38, loss 2.3016103291511536, acc 0.08
user 74, loss 2.2971706378459933, acc 0.1
user 67, loss 2.296468582749367, acc 0.16
user 53, loss 2.2999628007411954, acc 0.1
user 45, loss 2.3005311596393585, acc 0.1
user 69, loss 2.2923691499233247, acc 0.06
user 29, loss 2.296527934074402, acc 0.1
user 41, loss 2.3008989661931993, acc 0.1
user 11, loss 2.302001647353172, acc 0.12
user 75, loss 2.3014721947908403, acc 0.14
 
Avg Training Stats after 13 global rounds:
Training Loss : 2.298240131215407
Global model Benign Test Accuracy: 9.52% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 229.46 , Outputs: tensor([0.1008])


 | Global Training Round : 14 |

user 40, loss 2.296162750124931, acc 0.1
user 58, loss 2.299140901565552, acc 0.08
user 97, loss 2.3004520791769028, acc 0.1
user 57, loss 2.299824427962303, acc 0.1
user 89, loss 2.2950777053833007, acc 0.08
user 20, loss 2.299817202091217, acc 0.04
user 32, loss 2.294402062892914, acc 0.1
user 29, loss 2.2943453073501585, acc 0.1
user 78, loss 2.2938762265443797, acc 0.08
user 26, loss 2.3005252116918564, acc 0.18
 
Avg Training Stats after 14 global rounds:
Training Loss : 2.2981774352341886
Global model Benign Test Accuracy: 10.14% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 232.97 , Outputs: tensor([0.0973])


 | Global Training Round : 15 |

user 71, loss 2.3010629773139955, acc 0.1
user 45, loss 2.3013980263471603, acc 0.1
user 94, loss 2.300168651938438, acc 0.06
user 50, loss 2.301820818185806, acc 0.16
user 27, loss 2.2951053816080096, acc 0.08
user 0, loss 2.299247666597366, acc 0.12
user 48, loss 2.2986155480146406, acc 0.06
user 80, loss 2.2997685897350313, acc 0.12
user 43, loss 2.2954491859674455, acc 0.08
user 9, loss 2.2961544603109356, acc 0.1
 
Avg Training Stats after 15 global rounds:
Training Loss : 2.2982242149253684
Global model Benign Test Accuracy: 9.73% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 229.64 , Outputs: tensor([0.1006])


 | Global Training Round : 16 |

user 36, loss 2.294689227342606, acc 0.16
user 57, loss 2.2991382354497913, acc 0.1
user 96, loss 2.298169910311699, acc 0.12
user 18, loss 2.2946109420061114, acc 0.08
user 52, loss 2.2986225295066833, acc 0.14
user 91, loss 2.2988562685251237, acc 0.08
user 30, loss 2.298788268566132, acc 0.14
user 98, loss 2.294318246245384, acc 0.04
user 35, loss 2.2979576385021208, acc 0.12
user 16, loss 2.3002727884054184, acc 0.14
 
Avg Training Stats after 16 global rounds:
Training Loss : 2.2981816018354144
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.13 , Outputs: tensor([0.1042])


 | Global Training Round : 17 |

user 4, loss 2.300052223205566, acc 0.12
user 25, loss 2.2968343883752818, acc 0.04
user 62, loss 2.2964885193109508, acc 0.02
user 60, loss 2.295767000317573, acc 0.1
user 93, loss 2.2949567037820815, acc 0.16
user 66, loss 2.2946809458732607, acc 0.06
user 11, loss 2.3023501771688464, acc 0.12
user 27, loss 2.294938141107559, acc 0.08
user 22, loss 2.297280874848366, acc 0.16
user 96, loss 2.2970239186286925, acc 0.12
 
Avg Training Stats after 17 global rounds:
Training Loss : 2.2981142893310853
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 227.28 , Outputs: tensor([0.1030])


 | Global Training Round : 18 |

user 47, loss 2.3003010874986645, acc 0.12
user 27, loss 2.293660342097282, acc 0.08
user 86, loss 2.2984851825237276, acc 0.06
user 88, loss 2.2990662169456484, acc 0.2
user 81, loss 2.2979062819480895, acc 0.16
user 78, loss 2.2942013442516327, acc 0.08
Malcious user 7 is selected!
user 7, loss 2.2073214769363405, acc 0.12, mal loss 2.1145739555358887, mal acc 1.0
user 74, loss 2.2970765334367753, acc 0.1
user 66, loss 2.293015334606171, acc 0.06
user 0, loss 2.2982527327537534, acc 0.12
 
Avg Training Stats after 18 global rounds:
Training Loss : 2.2975484206626806
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 220.16 , Outputs: tensor([0.1106])


 | Global Training Round : 19 |

user 27, loss 2.292961043715477, acc 0.08
user 44, loss 2.2959321695566177, acc 0.08
user 61, loss 2.3022413218021396, acc 0.08
user 64, loss 2.3008577716350556, acc 0.16
user 70, loss 2.2975821751356125, acc 0.04
user 52, loss 2.298024686574936, acc 0.04
user 12, loss 2.298822399377823, acc 0.16
user 30, loss 2.2999295687675474, acc 0.14
user 24, loss 2.2973536175489424, acc 0.1
user 81, loss 2.297565657496452, acc 0.16
 
Avg Training Stats after 19 global rounds:
Training Loss : 2.2975788743731216
Global model Benign Test Accuracy: 7.61% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.43 , Outputs: tensor([0.1049])


 | Global Training Round : 20 |

user 38, loss 2.301636930108071, acc 0.08
user 31, loss 2.2999989122152327, acc 0.1
user 99, loss 2.2998479980230333, acc 0.08
user 34, loss 2.2965881276130675, acc 0.12
user 1, loss 2.302460720539093, acc 0.14
user 18, loss 2.2946260952949524, acc 0.08
user 15, loss 2.301887097358704, acc 0.06
user 73, loss 2.2977162760496137, acc 0.1
user 36, loss 2.2952823370695112, acc 0.16
user 8, loss 2.2989478981494904, acc 0.16
 
Avg Training Stats after 20 global rounds:
Training Loss : 2.2976448926165696
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.86 , Outputs: tensor([0.1055])


 | Global Training Round : 21 |

user 85, loss 2.2986811178922655, acc 0.14
user 25, loss 2.297238219380379, acc 0.04
user 83, loss 2.2982753711938857, acc 0.12
user 56, loss 2.2987601304054257, acc 0.06
user 84, loss 2.301130547523498, acc 0.1
user 16, loss 2.300468881726265, acc 0.14
user 27, loss 2.2938904613256454, acc 0.08
user 53, loss 2.3000873917341234, acc 0.1
user 39, loss 2.2960608464479444, acc 0.1
user 74, loss 2.296814466118813, acc 0.1
 
Avg Training Stats after 21 global rounds:
Training Loss : 2.2976685045574388
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.07 , Outputs: tensor([0.1064])


 | Global Training Round : 22 |

user 24, loss 2.2971073752641678, acc 0.1
user 39, loss 2.2947420215606686, acc 0.1
user 59, loss 2.296746129989624, acc 0.06
user 47, loss 2.3011321872472763, acc 0.12
user 18, loss 2.2938744658231736, acc 0.08
user 44, loss 2.2948459887504575, acc 0.08
user 91, loss 2.3001442778110506, acc 0.08
user 12, loss 2.2993432146310804, acc 0.16
user 90, loss 2.2995508289337154, acc 0.08
user 36, loss 2.2949319994449615, acc 0.16
 
Avg Training Stats after 22 global rounds:
Training Loss : 2.297649111120538
Global model Benign Test Accuracy: 11.16% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.49 , Outputs: tensor([0.1018])


 | Global Training Round : 23 |

user 17, loss 2.2999153769016263, acc 0.08
user 21, loss 2.302729340791702, acc 0.06
user 63, loss 2.293843767642975, acc 0.16
user 14, loss 2.300629007220268, acc 0.12
user 6, loss 2.301302088499069, acc 0.1
user 76, loss 2.297149986028671, acc 0.08
user 32, loss 2.2941684830188755, acc 0.06
user 34, loss 2.2960827308893204, acc 0.12
user 50, loss 2.301505531668663, acc 0.16
user 92, loss 2.2993915587663647, acc 0.08
 
Avg Training Stats after 23 global rounds:
Training Loss : 2.2976935752954164
Global model Benign Test Accuracy: 10.00% 
 23%|██▎       | 23/100 [10:56<37:08, 28.94s/it] 24%|██▍       | 24/100 [11:25<36:43, 28.99s/it] 25%|██▌       | 25/100 [11:54<36:16, 29.02s/it] 26%|██▌       | 26/100 [12:24<35:49, 29.05s/it] 27%|██▋       | 27/100 [12:53<35:22, 29.07s/it] 28%|██▊       | 28/100 [13:19<33:54, 28.26s/it] 29%|██▉       | 29/100 [13:48<33:44, 28.52s/it] 30%|███       | 30/100 [14:17<33:28, 28.69s/it] 31%|███       | 31/100 [14:46<33:08, 28.82s/it] 32%|███▏      | 32/100 [15:15<32:45, 28.90s/it] 33%|███▎      | 33/100 [15:45<32:20, 28.96s/it] 34%|███▍      | 34/100 [16:14<31:53, 28.99s/it]
Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.47 , Outputs: tensor([0.0998])


 | Global Training Round : 24 |

user 34, loss 2.295509689450264, acc 0.12
user 73, loss 2.297905662059784, acc 0.1
user 62, loss 2.296120868325233, acc 0.02
user 19, loss 2.298685067892075, acc 0.06
user 17, loss 2.299996183514595, acc 0.08
user 37, loss 2.300696645379067, acc 0.06
user 30, loss 2.299165424108505, acc 0.14
user 89, loss 2.296700546741486, acc 0.08
user 70, loss 2.2992445278167724, acc 0.04
user 31, loss 2.30074362039566, acc 0.1
 
Avg Training Stats after 24 global rounds:
Training Loss : 2.2977262106401226
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.78 , Outputs: tensor([0.1035])


 | Global Training Round : 25 |

user 12, loss 2.2991681635379786, acc 0.16
user 75, loss 2.3008544170856475, acc 0.1
user 65, loss 2.2997268307209016, acc 0.08
user 16, loss 2.299633078575134, acc 0.14
user 60, loss 2.295589015483856, acc 0.06
user 70, loss 2.2984554606676104, acc 0.04
user 98, loss 2.292921209335327, acc 0.04
user 52, loss 2.2980116206407546, acc 0.14
user 13, loss 2.300655871629715, acc 0.04
user 18, loss 2.294095029830933, acc 0.08
 
Avg Training Stats after 25 global rounds:
Training Loss : 2.2977336050045487
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.63 , Outputs: tensor([0.1058])


 | Global Training Round : 26 |

user 26, loss 2.299912250638008, acc 0.18
user 96, loss 2.2986481469869617, acc 0.12
user 44, loss 2.294692302346229, acc 0.08
user 70, loss 2.297972168922424, acc 0.04
user 39, loss 2.2958786088228225, acc 0.1
user 74, loss 2.296645053625107, acc 0.1
user 34, loss 2.295800234079361, acc 0.12
user 37, loss 2.300008714199066, acc 0.06
user 19, loss 2.298719909787178, acc 0.06
user 80, loss 2.300473660826683, acc 0.06
 
Avg Training Stats after 26 global rounds:
Training Loss : 2.2977390473129655
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.93 , Outputs: tensor([0.1024])


 | Global Training Round : 27 |

user 72, loss 2.2993404942750932, acc 0.1
user 88, loss 2.2995031994581225, acc 0.2
user 34, loss 2.294623038172722, acc 0.12
user 16, loss 2.29952156841755, acc 0.06
user 62, loss 2.294580290317535, acc 0.02
user 31, loss 2.3007292532920838, acc 0.1
user 71, loss 2.3008074074983593, acc 0.1
user 13, loss 2.3011161410808563, acc 0.04
user 44, loss 2.2937728261947634, acc 0.08
user 55, loss 2.297122402191162, acc 0.12
 
Avg Training Stats after 27 global rounds:
Training Loss : 2.2977528478602567
Global model Benign Test Accuracy: 8.66% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.34 , Outputs: tensor([0.0999])


 | Global Training Round : 28 |

user 13, loss 2.3007495927810666, acc 0.04
user 44, loss 2.2935963851213454, acc 0.08
user 32, loss 2.296334232091904, acc 0.06
user 55, loss 2.297043635249138, acc 0.12
user 77, loss 2.2968603491783144, acc 0.18
user 9, loss 2.2961084389686586, acc 0.14
Malcious user 7 is selected!
user 7, loss 2.2373770475387573, acc 0.12, mal loss 2.1439249515533447, mal acc 1.0
user 50, loss 2.301629168987274, acc 0.16
user 6, loss 2.300426064729691, acc 0.1
user 61, loss 2.3020138251781463, acc 0.1
 
Avg Training Stats after 28 global rounds:
Training Loss : 2.29755502736462
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 223.06 , Outputs: tensor([0.1075])


 | Global Training Round : 29 |

user 91, loss 2.3001806008815766, acc 0.08
user 67, loss 2.296305885910988, acc 0.02
user 39, loss 2.2956139785051346, acc 0.1
user 70, loss 2.298631585240364, acc 0.04
user 93, loss 2.2976670378446578, acc 0.16
user 4, loss 2.3013161277770995, acc 0.12
user 48, loss 2.2983548891544343, acc 0.06
user 87, loss 2.302827832698822, acc 0.08
user 88, loss 2.2990501052141186, acc 0.1
user 35, loss 2.2982207506895067, acc 0.12
 
Avg Training Stats after 29 global rounds:
Training Loss : 2.2975985395034835
Global model Benign Test Accuracy: 12.12% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 226.33 , Outputs: tensor([0.1040])


 | Global Training Round : 30 |

user 49, loss 2.296131825447082, acc 0.06
user 6, loss 2.3014927738904953, acc 0.1
user 94, loss 2.3011163198947906, acc 0.06
user 62, loss 2.2948424220085144, acc 0.02
user 3, loss 2.2943503016233446, acc 0.14
user 81, loss 2.2981946325302123, acc 0.16
user 47, loss 2.299912681579589, acc 0.12
user 36, loss 2.2945965296030044, acc 0.16
user 63, loss 2.2933684557676317, acc 0.16
user 31, loss 2.300687944293022, acc 0.1
 
Avg Training Stats after 30 global rounds:
Training Loss : 2.297594234475493
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 223.09 , Outputs: tensor([0.1074])


 | Global Training Round : 31 |

user 31, loss 2.299705009460449, acc 0.1
user 25, loss 2.298463307619095, acc 0.04
user 54, loss 2.300730065703392, acc 0.1
user 14, loss 2.301708397269249, acc 0.12
user 26, loss 2.3007681339979174, acc 0.18
user 50, loss 2.3017645138502116, acc 0.04
user 68, loss 2.2973857271671294, acc 0.14
user 55, loss 2.29918020606041, acc 0.08
user 21, loss 2.302777487039566, acc 0.06
user 86, loss 2.2982049620151517, acc 0.06
 
Avg Training Stats after 31 global rounds:
Training Loss : 2.2976740585575177
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.15 , Outputs: tensor([0.0991])


 | Global Training Round : 32 |

user 85, loss 2.299386387467384, acc 0.14
user 91, loss 2.2999357044696804, acc 0.08
user 9, loss 2.295047908425331, acc 0.14
user 35, loss 2.2969804894924164, acc 0.12
user 37, loss 2.3009760987758634, acc 0.06
user 97, loss 2.3001065176725386, acc 0.14
user 40, loss 2.29737971007824, acc 0.1
user 47, loss 2.3000231206417086, acc 0.12
user 71, loss 2.30001158118248, acc 0.1
user 82, loss 2.296316794157028, acc 0.1
 
Avg Training Stats after 32 global rounds:
Training Loss : 2.2977035077037287
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.25 , Outputs: tensor([0.0990])


 | Global Training Round : 33 |

user 71, loss 2.300468929409981, acc 0.1
user 42, loss 2.2952870148420335, acc 0.14
user 24, loss 2.295471377968788, acc 0.1
user 91, loss 2.2985822170972825, acc 0.08
user 59, loss 2.297717796564102, acc 0.14
user 43, loss 2.295521201491356, acc 0.08
user 12, loss 2.29798720061779, acc 0.16
user 33, loss 2.298555792570114, acc 0.12
user 90, loss 2.297101210355759, acc 0.08
user 21, loss 2.3023194313049316, acc 0.06
 
Avg Training Stats after 33 global rounds:
Training Loss : 2.2977094989012588
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 233.11 , Outputs: tensor([0.0972])


 | Global Training Round : 34 |

user 26, loss 2.2996956562995914, acc 0.18
user 51, loss 2.301587501764297, acc 0.1
user 32, loss 2.293822463750839, acc 0.06
user 37, loss 2.301397923231125, acc 0.06
user 67, loss 2.297205958962441, acc 0.16
user 2, loss 2.298709387779236, acc 0.1
user 6, loss 2.3022191387414934, acc 0.1
user 71, loss 2.301090087294579, acc 0.1
user 36, loss 2.293719238638878, acc 0.16
user 73, loss 2.2977592378854754, acc 0.1
 
Avg Training Stats after 34 global rounds:
Training Loss : 2.2977392389169506
Global model Benign Test Accuracy: 12.95% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.98 , Outputs: tensor([0.1023])


 | Global Training Round : 35 |

user 49, loss 2.2965223062038422, acc 0.06
user 93, loss 2.295125126838684, acc 0.16
user 83, loss 2.2981257045269015, acc 0.12
user 99, loss 2.300593367218971, acc 0.08
user 42, loss 2.293074077963829, acc 0.14
user 4, loss 2.2998522776365276, acc 0.12
user 34, loss 2.2963082820177076, acc 0.12
user 62, loss 2.297122120261193, acc 0.02
user 8, loss 2.3001863330602648, acc 0.08
user 73, loss 2.2966160839796066, acc 0.1
 
Avg Training Stats after 35 global rounds:
Training Loss : 2.2977281911756307
Global model Benign Test Accuracy: 10.64% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 226.95 , Outputs: tensor([0.1034])
 35%|███▌      | 35/100 [16:43<31:25, 29.01s/it] 36%|███▌      | 36/100 [17:12<30:58, 29.04s/it] 37%|███▋      | 37/100 [17:38<29:39, 28.24s/it] 38%|███▊      | 38/100 [18:07<29:27, 28.51s/it] 39%|███▉      | 39/100 [18:36<29:09, 28.69s/it] 40%|████      | 40/100 [19:06<28:48, 28.81s/it] 41%|████      | 41/100 [19:35<28:25, 28.91s/it] 42%|████▏     | 42/100 [20:01<27:12, 28.14s/it] 43%|████▎     | 43/100 [20:30<27:00, 28.43s/it] 44%|████▍     | 44/100 [20:59<26:43, 28.63s/it] 45%|████▌     | 45/100 [21:28<26:22, 28.77s/it] 46%|████▌     | 46/100 [21:57<25:58, 28.86s/it]

 | Global Training Round : 36 |

user 29, loss 2.2959058159589767, acc 0.1
user 12, loss 2.2984022980928427, acc 0.16
user 79, loss 2.2984396171569825, acc 0.1
user 17, loss 2.300809959769249, acc 0.06
user 40, loss 2.2957256013154987, acc 0.1
user 94, loss 2.2999272888898847, acc 0.06
user 0, loss 2.2976798129081724, acc 0.12
user 60, loss 2.296355125904083, acc 0.06
user 23, loss 2.2959585475921633, acc 0.1
user 48, loss 2.297528262138367, acc 0.06
 
Avg Training Stats after 36 global rounds:
Training Loss : 2.2977266645588807
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.64 , Outputs: tensor([0.1026])


 | Global Training Round : 37 |

user 51, loss 2.300593456029892, acc 0.1
user 13, loss 2.3008634877204894, acc 0.14
user 9, loss 2.2949853891134264, acc 0.1
user 98, loss 2.2940462934970856, acc 0.04
user 64, loss 2.301359658837318, acc 0.16
user 23, loss 2.295291750431061, acc 0.1
user 24, loss 2.29644446849823, acc 0.1
user 22, loss 2.297193653583527, acc 0.16
Malcious user 7 is selected!
user 7, loss 2.210876393318176, acc 0.12, mal loss 2.118042230606079, mal acc 1.0
user 96, loss 2.2986675268411636, acc 0.12
 
Avg Training Stats after 37 global rounds:
Training Loss : 2.2974916792407227
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 219.40 , Outputs: tensor([0.1115])


 | Global Training Round : 38 |

user 51, loss 2.300333325266838, acc 0.1
user 1, loss 2.3026363265514376, acc 0.14
user 84, loss 2.30164615035057, acc 0.1
user 98, loss 2.2924213814735417, acc 0.04
user 97, loss 2.2997949373722077, acc 0.14
user 3, loss 2.2939935541152954, acc 0.14
user 6, loss 2.302005474567413, acc 0.1
user 72, loss 2.299528393149376, acc 0.1
user 41, loss 2.3016002410650254, acc 0.1
user 76, loss 2.297253743410111, acc 0.08
 
Avg Training Stats after 38 global rounds:
Training Loss : 2.297534565385235
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.96 , Outputs: tensor([0.1054])


 | Global Training Round : 39 |

user 59, loss 2.296498717069626, acc 0.06
user 63, loss 2.295291066765785, acc 0.16
user 99, loss 2.3008611029386516, acc 0.08
user 66, loss 2.2957526820898058, acc 0.06
user 76, loss 2.295093732476235, acc 0.08
user 90, loss 2.3000198441743853, acc 0.08
user 53, loss 2.2999009054899213, acc 0.1
user 39, loss 2.2956035715341567, acc 0.1
user 91, loss 2.3004398757219313, acc 0.08
user 18, loss 2.2945807629823687, acc 0.08
 
Avg Training Stats after 39 global rounds:
Training Loss : 2.2975312233529026
Global model Benign Test Accuracy: 6.31% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.61 , Outputs: tensor([0.1048])


 | Global Training Round : 40 |

user 12, loss 2.2987918406724934, acc 0.16
user 11, loss 2.301852199435234, acc 0.12
user 55, loss 2.29804764509201, acc 0.08
user 88, loss 2.298663029074669, acc 0.2
user 13, loss 2.3009891337156296, acc 0.04
user 44, loss 2.294709248542785, acc 0.08
user 37, loss 2.2997550225257877, acc 0.06
user 46, loss 2.2996724116802216, acc 0.06
user 19, loss 2.297601125836372, acc 0.06
user 53, loss 2.298929629921913, acc 0.1
 
Avg Training Stats after 40 global rounds:
Training Loss : 2.2975654709853233
Global model Benign Test Accuracy: 9.77% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.83 , Outputs: tensor([0.1025])


 | Global Training Round : 41 |

user 92, loss 2.300169873833656, acc 0.08
user 98, loss 2.2941372811794283, acc 0.04
user 6, loss 2.3009606969356535, acc 0.1
user 85, loss 2.2999999171495444, acc 0.14
user 2, loss 2.297995609641075, acc 0.1
user 99, loss 2.3007478600740434, acc 0.08
user 79, loss 2.2989811915159226, acc 0.1
user 59, loss 2.297279854416847, acc 0.14
user 32, loss 2.2965076798200608, acc 0.06
user 1, loss 2.3023524498939514, acc 0.14
 
Avg Training Stats after 41 global rounds:
Training Loss : 2.297598343435584
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.63 , Outputs: tensor([0.1047])


 | Global Training Round : 42 |

user 93, loss 2.2969220489263535, acc 0.16
user 1, loss 2.302264640927315, acc 0.14
user 71, loss 2.3001166701316835, acc 0.1
user 94, loss 2.2993483585119248, acc 0.06
user 0, loss 2.298220083117485, acc 0.12
user 42, loss 2.2943549180030827, acc 0.14
user 70, loss 2.2990323233604433, acc 0.04
user 6, loss 2.3016588073968887, acc 0.1
Malcious user 7 is selected!
user 7, loss 2.1910547733306887, acc 0.12, mal loss 2.098689317703247, mal acc 1.0
user 88, loss 2.298401572704315, acc 0.2
 
Avg Training Stats after 42 global rounds:
Training Loss : 2.2973730833452373
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 217.43 , Outputs: tensor([0.1137])


 | Global Training Round : 43 |

user 52, loss 2.298614389896393, acc 0.04
user 82, loss 2.2990283238887783, acc 0.1
user 92, loss 2.3004496508836745, acc 0.1
user 79, loss 2.2974739533662794, acc 0.1
user 35, loss 2.298434374332428, acc 0.12
user 25, loss 2.2970824015140536, acc 0.04
user 22, loss 2.296361829042435, acc 0.16
user 21, loss 2.303201207518577, acc 0.06
user 59, loss 2.2978638178110122, acc 0.14
user 44, loss 2.2960648554563523, acc 0.08
 
Avg Training Stats after 43 global rounds:
Training Loss : 2.29739830188072
Global model Benign Test Accuracy: 6.49% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.44 , Outputs: tensor([0.1049])


 | Global Training Round : 44 |

user 3, loss 2.296000507473946, acc 0.14
user 65, loss 2.3000298756361004, acc 0.1
user 44, loss 2.2946407252550123, acc 0.08
user 25, loss 2.29615197300911, acc 0.04
user 90, loss 2.298750869035721, acc 0.08
user 35, loss 2.297572628855705, acc 0.12
user 83, loss 2.298188812732697, acc 0.12
user 47, loss 2.300619369745254, acc 0.12
user 38, loss 2.301614934206009, acc 0.08
user 0, loss 2.2990109229087827, acc 0.12
 
Avg Training Stats after 44 global rounds:
Training Loss : 2.297417841880836
Global model Benign Test Accuracy: 6.26% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.54 , Outputs: tensor([0.1048])


 | Global Training Round : 45 |

user 67, loss 2.2967349243164064, acc 0.02
user 80, loss 2.2999863046407696, acc 0.06
user 52, loss 2.298555209636688, acc 0.14
user 5, loss 2.2956721287965776, acc 0.06
user 64, loss 2.300888613462448, acc 0.06
user 83, loss 2.298484840989113, acc 0.12
user 32, loss 2.2946125173568723, acc 0.06
user 69, loss 2.2939113324880602, acc 0.06
user 27, loss 2.294149435162544, acc 0.08
user 74, loss 2.2971401917934418, acc 0.1
 
Avg Training Stats after 45 global rounds:
Training Loss : 2.2974088576138016
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 223.94 , Outputs: tensor([0.1065])


 | Global Training Round : 46 |

user 83, loss 2.297788756489754, acc 0.12
user 97, loss 2.3001950860023497, acc 0.14
user 36, loss 2.293681455254555, acc 0.16
user 64, loss 2.301072530150413, acc 0.16
user 46, loss 2.3000281625986103, acc 0.14
user 16, loss 2.299678012728691, acc 0.14
user 72, loss 2.2987897872924803, acc 0.1
user 84, loss 2.3016422104835508, acc 0.04
user 30, loss 2.2988478273153303, acc 0.14
user 17, loss 2.3007469135522842, acc 0.06
 
Avg Training Stats after 46 global rounds:
Training Loss : 2.2974488188436495
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 225.98 , Outputs: tensor([0.1044])


 | Global Training Round : 47 |

user 3, loss 2.293887888193131, acc 0.14
user 26, loss 2.3003477096557616, acc 0.18
user 61, loss 2.30198421061039, acc 0.08
user 56, loss 2.2984131157398227, acc 0.06
user 65, loss 2.3004076832532885, acc 0.1
user 33, loss 2.2974439102411273, acc 0.12
user 18, loss 2.294836015105248, acc 0.08
user 23, loss 2.29536919593811, acc 0.1
user 62, loss 2.2956607782840726, acc 0.02
user 17, loss 2.300422750711441, acc 0.06
 
Avg Training Stats after 47 global rounds:
Training Loss : 2.2974579360123646
Global model Benign Test Accuracy: 8.44% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.04 , Outputs: tensor([0.1022])
 47%|████▋     | 47/100 [22:26<25:30, 28.87s/it] 48%|████▊     | 48/100 [22:55<25:01, 28.87s/it] 49%|████▉     | 49/100 [23:24<24:32, 28.87s/it] 50%|█████     | 50/100 [23:53<24:03, 28.88s/it] 51%|█████     | 51/100 [24:22<23:35, 28.89s/it] 52%|█████▏    | 52/100 [24:51<23:07, 28.90s/it] 53%|█████▎    | 53/100 [25:20<22:38, 28.90s/it] 54%|█████▍    | 54/100 [25:49<22:09, 28.90s/it] 55%|█████▌    | 55/100 [26:17<21:40, 28.90s/it] 56%|█████▌    | 56/100 [26:46<21:11, 28.90s/it] 57%|█████▋    | 57/100 [27:15<20:42, 28.91s/it] 58%|█████▊    | 58/100 [27:44<20:14, 28.91s/it] 59%|█████▉    | 59/100 [28:13<19:45, 28.90s/it]

 | Global Training Round : 48 |

user 29, loss 2.294490434527397, acc 0.2
user 30, loss 2.2989951729774476, acc 0.14
user 62, loss 2.2943709921836852, acc 0.02
user 70, loss 2.29921522974968, acc 0.04
user 43, loss 2.29727342069149, acc 0.08
user 87, loss 2.3023119056224823, acc 0.08
user 0, loss 2.2976220142841344, acc 0.12
user 16, loss 2.2991075295209886, acc 0.14
user 49, loss 2.2957868796586993, acc 0.06
user 45, loss 2.301032987833023, acc 0.1
 
Avg Training Stats after 48 global rounds:
Training Loss : 2.2974696593601256
Global model Benign Test Accuracy: 8.39% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.85 , Outputs: tensor([0.1014])


 | Global Training Round : 49 |

user 50, loss 2.3024513816833494, acc 0.16
user 25, loss 2.2988273274898527, acc 0.04
user 28, loss 2.296270245909691, acc 0.1
user 11, loss 2.3029267090559005, acc 0.12
user 59, loss 2.2968333929777143, acc 0.14
user 17, loss 2.301294448971748, acc 0.08
user 82, loss 2.2973373782634736, acc 0.1
user 21, loss 2.302702096104622, acc 0.06
user 63, loss 2.294962850809097, acc 0.16
user 16, loss 2.2988760209083563, acc 0.14
 
Avg Training Stats after 49 global rounds:
Training Loss : 2.297505955806192
Global model Benign Test Accuracy: 9.50% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.79 , Outputs: tensor([0.0995])


 | Global Training Round : 50 |

user 80, loss 2.30008650124073, acc 0.06
user 62, loss 2.2953623431921004, acc 0.02
user 98, loss 2.292902413606644, acc 0.04
user 39, loss 2.295772497057915, acc 0.1
user 21, loss 2.3021657598018646, acc 0.06
user 61, loss 2.301746650338173, acc 0.08
user 64, loss 2.300710797905922, acc 0.06
user 1, loss 2.302058115005493, acc 0.14
user 88, loss 2.2987417739629747, acc 0.2
user 83, loss 2.2989961761236186, acc 0.12
 
Avg Training Stats after 50 global rounds:
Training Loss : 2.297532922746539
Global model Benign Test Accuracy: 9.46% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.07 , Outputs: tensor([0.1032])


 | Global Training Round : 51 |

user 67, loss 2.297031594514847, acc 0.02
user 29, loss 2.2951160687208176, acc 0.2
user 72, loss 2.2992793244123453, acc 0.1
user 58, loss 2.298878048658371, acc 0.08
user 89, loss 2.2967280775308607, acc 0.12
user 85, loss 2.2993849247694014, acc 0.14
user 24, loss 2.2973723423480985, acc 0.1
user 6, loss 2.300913783311844, acc 0.1
user 77, loss 2.296179332137108, acc 0.18
user 14, loss 2.301047558784485, acc 0.12
 
Avg Training Stats after 51 global rounds:
Training Loss : 2.29754586750678
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.04 , Outputs: tensor([0.0992])


 | Global Training Round : 52 |

user 66, loss 2.293666478991508, acc 0.06
user 14, loss 2.3009004789590835, acc 0.12
user 46, loss 2.300167511701584, acc 0.14
user 38, loss 2.301987683773041, acc 0.08
user 79, loss 2.2987975996732706, acc 0.1
user 74, loss 2.295590997934341, acc 0.1
user 67, loss 2.296090798377991, acc 0.16
user 41, loss 2.3006509488821028, acc 0.02
user 40, loss 2.296481895446777, acc 0.1
user 73, loss 2.298088725209236, acc 0.1
 
Avg Training Stats after 52 global rounds:
Training Loss : 2.29755926066809
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.02 , Outputs: tensor([0.0992])


 | Global Training Round : 53 |

user 70, loss 2.2985676163434983, acc 0.04
user 45, loss 2.3013151508569716, acc 0.1
user 60, loss 2.2965850102901455, acc 0.06
user 87, loss 2.3020399838685988, acc 0.06
user 16, loss 2.3001594585180287, acc 0.14
user 55, loss 2.2979637360572815, acc 0.12
user 2, loss 2.2988324731588365, acc 0.1
user 43, loss 2.2947466027736665, acc 0.08
user 25, loss 2.2985427355766297, acc 0.04
user 38, loss 2.3013211703300476, acc 0.08
 
Avg Training Stats after 53 global rounds:
Training Loss : 2.2975865839343026
Global model Benign Test Accuracy: 10.41% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 229.75 , Outputs: tensor([0.1005])


 | Global Training Round : 54 |

user 34, loss 2.2959708529710774, acc 0.12
user 36, loss 2.293741776943207, acc 0.16
user 96, loss 2.298564041256905, acc 0.12
user 4, loss 2.3002340441942213, acc 0.12
user 8, loss 2.2986944448947906, acc 0.08
user 45, loss 2.3007734954357146, acc 0.1
user 47, loss 2.2995105397701265, acc 0.12
user 72, loss 2.2987517750263216, acc 0.1
user 76, loss 2.2962147206068035, acc 0.18
user 65, loss 2.3002960395812986, acc 0.08
 
Avg Training Stats after 54 global rounds:
Training Loss : 2.297599335584928
Global model Benign Test Accuracy: 8.38% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 232.75 , Outputs: tensor([0.0975])


 | Global Training Round : 55 |

user 96, loss 2.2978249090909957, acc 0.12
user 18, loss 2.295573390722274, acc 0.08
user 48, loss 2.2986135834455492, acc 0.06
user 58, loss 2.298833652734756, acc 0.06
user 37, loss 2.3014972388744352, acc 0.06
user 82, loss 2.2955194580554963, acc 0.1
user 79, loss 2.2993940234184262, acc 0.1
user 98, loss 2.292928848862648, acc 0.12
user 0, loss 2.29901544213295, acc 0.12
user 65, loss 2.3002181929349903, acc 0.06
 
Avg Training Stats after 55 global rounds:
Training Loss : 2.2976055635566066
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 227.73 , Outputs: tensor([0.1026])


 | Global Training Round : 56 |

user 72, loss 2.298279268145561, acc 0.1
user 84, loss 2.3009813451766967, acc 0.1
user 17, loss 2.3000345081090927, acc 0.06
user 6, loss 2.3016768580675127, acc 0.1
user 69, loss 2.294485005140305, acc 0.06
user 1, loss 2.3025832879543304, acc 0.14
user 10, loss 2.3014370363950727, acc 0.08
user 65, loss 2.3002969813346867, acc 0.08
user 62, loss 2.2964033883810044, acc 0.02
user 45, loss 2.3002926003932953, acc 0.1
 
Avg Training Stats after 56 global rounds:
Training Loss : 2.297642018277198
Global model Benign Test Accuracy: 8.90% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.06 , Outputs: tensor([0.1002])


 | Global Training Round : 57 |

user 20, loss 2.2993919587135316, acc 0.04
user 61, loss 2.302197311520577, acc 0.1
user 94, loss 2.2988513028621673, acc 0.06
user 6, loss 2.300781924724579, acc 0.1
user 2, loss 2.2976106178760527, acc 0.1
user 25, loss 2.296978437900543, acc 0.04
user 86, loss 2.2987095350027085, acc 0.06
user 95, loss 2.3005130797624584, acc 0.24
user 98, loss 2.292426257133484, acc 0.12
user 11, loss 2.3026662439107897, acc 0.1
 
Avg Training Stats after 57 global rounds:
Training Loss : 2.2976660647449787
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 229.20 , Outputs: tensor([0.1011])


 | Global Training Round : 58 |

user 31, loss 2.300300033092499, acc 0.1
user 33, loss 2.29670315861702, acc 0.12
user 70, loss 2.2995186126232143, acc 0.04
user 87, loss 2.3029425328969957, acc 0.08
user 28, loss 2.296012645959854, acc 0.1
user 69, loss 2.2942793852090837, acc 0.06
user 16, loss 2.2999744904041295, acc 0.14
user 14, loss 2.3010210072994233, acc 0.12
user 95, loss 2.300094562768936, acc 0.24
user 44, loss 2.2954320460557933, acc 0.08
 
Avg Training Stats after 58 global rounds:
Training Loss : 2.297682647206146
Global model Benign Test Accuracy: 8.43% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 233.54 , Outputs: tensor([0.0968])


 | Global Training Round : 59 |

user 20, loss 2.2992465007305145, acc 0.04
user 31, loss 2.3006603997945785, acc 0.1
user 30, loss 2.297790795564652, acc 0.14
user 49, loss 2.2958587217330932, acc 0.06
user 92, loss 2.301134539246559, acc 0.08
user 0, loss 2.298744527697563, acc 0.12
user 47, loss 2.300885924100876, acc 0.12
user 38, loss 2.302125033140183, acc 0.08
user 15, loss 2.301755251884461, acc 0.06
user 41, loss 2.3007591646909717, acc 0.1
 
Avg Training Stats after 59 global rounds:
Training Loss : 2.297720163115505
Global model Benign Test Accuracy: 8.80% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.51 , Outputs: tensor([0.0988])


 | Global Training Round : 60 |

user 71, loss 2.2992765456438065, acc 0.1
user 78, loss 2.294115327596664, acc 0.08
user 73, loss 2.2974687075614932, acc 0.1 60%|██████    | 60/100 [28:42<19:15, 28.90s/it] 61%|██████    | 61/100 [29:08<18:14, 28.07s/it] 62%|██████▏   | 62/100 [29:37<17:56, 28.32s/it] 63%|██████▎   | 63/100 [30:06<17:34, 28.49s/it] 64%|██████▍   | 64/100 [30:35<17:10, 28.62s/it] 65%|██████▌   | 65/100 [31:04<16:44, 28.70s/it] 66%|██████▌   | 66/100 [31:30<15:49, 27.94s/it] 67%|██████▋   | 67/100 [31:56<15:04, 27.41s/it] 68%|██████▊   | 68/100 [32:25<14:51, 27.85s/it] 69%|██████▉   | 69/100 [32:54<14:33, 28.16s/it] 70%|███████   | 70/100 [33:23<14:11, 28.39s/it] 71%|███████   | 71/100 [33:52<13:47, 28.54s/it]
user 89, loss 2.2952637791633608, acc 0.08
user 39, loss 2.29505920290947, acc 0.1
user 12, loss 2.2996187925338742, acc 0.12
user 87, loss 2.302396008372307, acc 0.06
user 18, loss 2.2949296933412553, acc 0.08
user 33, loss 2.2977779215574268, acc 0.12
user 13, loss 2.3002204263210295, acc 0.04
 
Avg Training Stats after 60 global rounds:
Training Loss : 2.2977183710719147
Global model Benign Test Accuracy: 11.10% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 232.97 , Outputs: tensor([0.0973])


 | Global Training Round : 61 |

user 83, loss 2.2994759356975556, acc 0.12
user 24, loss 2.296073999404907, acc 0.1
user 37, loss 2.30103245973587, acc 0.06
user 42, loss 2.294747881293297, acc 0.14
user 43, loss 2.296116719841957, acc 0.08
user 29, loss 2.295159355998039, acc 0.1
user 63, loss 2.295433702468872, acc 0.16
Malcious user 7 is selected!
user 7, loss 2.263337993621826, acc 0.12, mal loss 2.1693015098571777, mal acc 1.0
user 32, loss 2.294389359354973, acc 0.06
user 91, loss 2.3004148203134536, acc 0.08
 
Avg Training Stats after 61 global rounds:
Training Loss : 2.2976511555260317
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 221.42 , Outputs: tensor([0.1092])


 | Global Training Round : 62 |

user 61, loss 2.3027592009305953, acc 0.08
user 86, loss 2.298820919394493, acc 0.06
user 21, loss 2.3037842613458634, acc 0.06
user 22, loss 2.2961385881900784, acc 0.16
user 38, loss 2.3016516798734665, acc 0.08
user 34, loss 2.297470224499703, acc 0.12
user 63, loss 2.292620456814766, acc 0.16
user 66, loss 2.2929737442731857, acc 0.06
user 69, loss 2.29374215900898, acc 0.06
user 29, loss 2.2971250379085535, acc 0.1
 
Avg Training Stats after 62 global rounds:
Training Loss : 2.2976520824889013
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.89 , Outputs: tensor([0.1014])


 | Global Training Round : 63 |

user 61, loss 2.3019520491361622, acc 0.08
user 1, loss 2.302489515542984, acc 0.14
user 0, loss 2.2992296290397642, acc 0.12
user 14, loss 2.300891333818436, acc 0.12
user 80, loss 2.299417366981506, acc 0.12
user 55, loss 2.2986284625530247, acc 0.12
user 67, loss 2.2966208279132845, acc 0.16
user 96, loss 2.2989583307504655, acc 0.12
user 83, loss 2.2992618995904923, acc 0.12
user 28, loss 2.2958472418785094, acc 0.1
 
Avg Training Stats after 63 global rounds:
Training Loss : 2.2976787107941643
Global model Benign Test Accuracy: 6.51% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.95 , Outputs: tensor([0.0983])


 | Global Training Round : 64 |

user 35, loss 2.297280887961388, acc 0.12
user 96, loss 2.2969088667631152, acc 0.12
user 24, loss 2.295049566626549, acc 0.1
user 73, loss 2.2972895467281345, acc 0.1
user 85, loss 2.2984123808145527, acc 0.14
user 72, loss 2.299722447991371, acc 0.1
user 68, loss 2.293855404853821, acc 0.08
user 29, loss 2.2960211956501007, acc 0.1
user 20, loss 2.299926946759224, acc 0.04
user 23, loss 2.2969976508617402, acc 0.1
 
Avg Training Stats after 64 global rounds:
Training Loss : 2.2976703948364596
Global model Benign Test Accuracy: 10.98% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 236.32 , Outputs: tensor([0.0941])


 | Global Training Round : 65 |

user 16, loss 2.2997955513000488, acc 0.14
user 34, loss 2.294496542215348, acc 0.12
user 71, loss 2.3003771775960926, acc 0.1
user 45, loss 2.3019066548347475, acc 0.1
user 72, loss 2.298872092366218, acc 0.1
user 20, loss 2.2989909470081327, acc 0.04
user 54, loss 2.3012112349271776, acc 0.1
user 70, loss 2.3000003898143766, acc 0.04
user 91, loss 2.299932055473328, acc 0.08
user 67, loss 2.296367806196213, acc 0.16
 
Avg Training Stats after 65 global rounds:
Training Loss : 2.2976938509954863
Global model Benign Test Accuracy: 8.86% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 232.85 , Outputs: tensor([0.0974])


 | Global Training Round : 66 |

user 57, loss 2.2993552565574644, acc 0.06
user 96, loss 2.2971120476722717, acc 0.12
user 68, loss 2.295114669799805, acc 0.08
user 53, loss 2.3004701387882234, acc 0.1
user 26, loss 2.2993672651052472, acc 0.18
user 94, loss 2.2996594309806824, acc 0.06
user 95, loss 2.300635036230087, acc 0.24
user 45, loss 2.30141026198864, acc 0.1
Malcious user 7 is selected!
user 7, loss 2.2621509790420533, acc 0.12, mal loss 2.1681437492370605, mal acc 1.0
user 0, loss 2.29839658498764, acc 0.12
 
Avg Training Stats after 66 global rounds:
Training Loss : 2.2976585982094213
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 224.52 , Outputs: tensor([0.1059])


 | Global Training Round : 67 |

user 89, loss 2.2960272401571276, acc 0.12
user 44, loss 2.295780230164528, acc 0.08
user 64, loss 2.3013210719823833, acc 0.16
user 28, loss 2.2972856843471523, acc 0.1
user 66, loss 2.2956050163507458, acc 0.06
Malcious user 7 is selected!
user 7, loss 2.180136561393738, acc 0.12, mal loss 2.0880281925201416, mal acc 1.0
user 17, loss 2.3003156554698942, acc 0.08
user 99, loss 2.3003641730546955, acc 0.08
user 92, loss 2.301082453131676, acc 0.08
user 59, loss 2.2963924390077595, acc 0.14
 
Avg Training Stats after 67 global rounds:
Training Loss : 2.297491022900415
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 218.10 , Outputs: tensor([0.1129])


 | Global Training Round : 68 |

user 1, loss 2.3026806044578554, acc 0.14
user 30, loss 2.2998593610525133, acc 0.14
user 40, loss 2.297476134300232, acc 0.1
user 74, loss 2.2967961543798445, acc 0.1
user 90, loss 2.299496803283691, acc 0.08
user 22, loss 2.296958130002022, acc 0.1
user 42, loss 2.2937503588199624, acc 0.08
user 78, loss 2.2963166499137877, acc 0.08
user 53, loss 2.299457676410675, acc 0.1
user 76, loss 2.2970255678892135, acc 0.18
 
Avg Training Stats after 68 global rounds:
Training Loss : 2.2974982393879233
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 227.20 , Outputs: tensor([0.1031])


 | Global Training Round : 69 |

user 1, loss 2.302402237653732, acc 0.14
user 64, loss 2.301047956943512, acc 0.06
user 65, loss 2.300372953414917, acc 0.1
user 23, loss 2.296449459195137, acc 0.1
user 96, loss 2.297232576608658, acc 0.12
user 60, loss 2.2957228523492814, acc 0.06
user 74, loss 2.2966675984859464, acc 0.1
user 12, loss 2.2991137146949767, acc 0.16
user 13, loss 2.301243305206299, acc 0.04
user 52, loss 2.298803473711014, acc 0.14
 
Avg Training Stats after 69 global rounds:
Training Loss : 2.297518636104422
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.65 , Outputs: tensor([0.1037])


 | Global Training Round : 70 |

user 73, loss 2.2972262722253793, acc 0.1
user 17, loss 2.3004739969968795, acc 0.08
user 72, loss 2.2988428443670275, acc 0.1
user 55, loss 2.29798956155777, acc 0.08
user 67, loss 2.2963428735733036, acc 0.02
user 12, loss 2.2992962551116944, acc 0.16
user 80, loss 2.300041996240616, acc 0.06
user 18, loss 2.2945242148637774, acc 0.08
user 78, loss 2.294239291548729, acc 0.08
user 21, loss 2.302458330392837, acc 0.06
 
Avg Training Stats after 70 global rounds:
Training Loss : 2.2975275636413275
Global model Benign Test Accuracy: 12.18% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.78 , Outputs: tensor([0.0995])


 | Global Training Round : 71 |

user 71, loss 2.3008756804466244, acc 0.1
user 50, loss 2.301654766201973, acc 0.16
user 88, loss 2.298742016553879, acc 0.2
user 46, loss 2.2994309824705126, acc 0.14
user 12, loss 2.2984486478567128, acc 0.16
user 79, loss 2.299257154464722, acc 0.1
user 47, loss 2.300123897790909, acc 0.12
user 92, loss 2.3007319718599315, acc 0.08
user 55, loss 2.2961533266305927, acc 0.08
user 54, loss 2.301334733366967, acc 0.1
 
Avg Training Stats after 71 global rounds:
Training Loss : 2.297557813699397
Global model Benign Test Accuracy: 9.88% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.34 , Outputs: tensor([0.0989])


 | Global Training Round : 72 |

user 84, loss 2.3021125167608263, acc 0.1 72%|███████▏  | 72/100 [34:18<12:59, 27.84s/it] 73%|███████▎  | 73/100 [34:47<12:41, 28.21s/it] 74%|███████▍  | 74/100 [35:16<12:20, 28.47s/it] 75%|███████▌  | 75/100 [35:45<11:55, 28.61s/it] 76%|███████▌  | 76/100 [36:14<11:28, 28.69s/it] 77%|███████▋  | 77/100 [36:43<11:01, 28.74s/it] 78%|███████▊  | 78/100 [37:12<10:33, 28.80s/it] 79%|███████▉  | 79/100 [37:40<10:05, 28.83s/it] 80%|████████  | 80/100 [38:09<09:36, 28.84s/it] 81%|████████  | 81/100 [38:38<09:08, 28.85s/it] 82%|████████▏ | 82/100 [39:07<08:39, 28.85s/it] 83%|████████▎ | 83/100 [39:36<08:10, 28.86s/it]
user 75, loss 2.3012772184610366, acc 0.1
user 87, loss 2.3016273826360703, acc 0.08
user 89, loss 2.2977455478906634, acc 0.08
user 38, loss 2.30171886742115, acc 0.08
user 15, loss 2.3021167796850204, acc 0.06
user 35, loss 2.2972180676460265, acc 0.12
user 0, loss 2.29873475253582, acc 0.12
Malcious user 7 is selected!
user 7, loss 2.247303771972656, acc 0.12, mal loss 2.153629779815674, mal acc 1.0
user 2, loss 2.298251563310623, acc 0.1
 
Avg Training Stats after 72 global rounds:
Training Loss : 2.297519658604016
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 223.03 , Outputs: tensor([0.1075])


 | Global Training Round : 73 |

user 9, loss 2.2945214921236037, acc 0.14
user 39, loss 2.296816873550415, acc 0.1
user 17, loss 2.300313546657562, acc 0.06
user 72, loss 2.2996786308288577, acc 0.1
user 44, loss 2.295025044679641, acc 0.08
user 46, loss 2.2998686695098876, acc 0.06
user 13, loss 2.301653670668602, acc 0.04
user 97, loss 2.299116281867027, acc 0.1
user 18, loss 2.2936021310091017, acc 0.08
user 50, loss 2.301413716673851, acc 0.16
 
Avg Training Stats after 73 global rounds:
Training Loss : 2.297528992126658
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.93 , Outputs: tensor([0.1034])


 | Global Training Round : 74 |

user 68, loss 2.295211911797524, acc 0.14
user 72, loss 2.3001586043834688, acc 0.1
user 12, loss 2.29849100291729, acc 0.12
user 0, loss 2.2984411311149597, acc 0.12
user 17, loss 2.299702879786491, acc 0.08
user 98, loss 2.293520076870918, acc 0.04
user 60, loss 2.2942111778259275, acc 0.06
user 97, loss 2.299029929637909, acc 0.1
user 50, loss 2.3019031184911727, acc 0.16
user 77, loss 2.2952138525247574, acc 0.18
 
Avg Training Stats after 74 global rounds:
Training Loss : 2.2975297945105546
Global model Benign Test Accuracy: 12.95% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.29 , Outputs: tensor([0.1020])


 | Global Training Round : 75 |

user 77, loss 2.294423098564148, acc 0.18
user 2, loss 2.29669750213623, acc 0.1
user 13, loss 2.301684069037438, acc 0.04
user 3, loss 2.297436415553093, acc 0.14
user 15, loss 2.3026575666666034, acc 0.06
user 73, loss 2.296390600204468, acc 0.1
user 52, loss 2.2993117761611943, acc 0.14
user 14, loss 2.3013541561365125, acc 0.12
user 58, loss 2.2998249107599262, acc 0.1
user 26, loss 2.298612818717957, acc 0.18
 
Avg Training Stats after 75 global rounds:
Training Loss : 2.2975472544689977
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.92 , Outputs: tensor([0.1013])


 | Global Training Round : 76 |

user 67, loss 2.2978589791059494, acc 0.02
user 71, loss 2.300563815832138, acc 0.1
user 6, loss 2.301090279221535, acc 0.1
user 56, loss 2.298725166916847, acc 0.06
user 17, loss 2.3000208950042724, acc 0.06
user 39, loss 2.295795317292213, acc 0.1
user 84, loss 2.300931738615036, acc 0.1
user 76, loss 2.295863823890686, acc 0.08
user 41, loss 2.3013088840246203, acc 0.1
user 12, loss 2.299155746102333, acc 0.16
 
Avg Training Stats after 76 global rounds:
Training Loss : 2.2975680993391494
Global model Benign Test Accuracy: 14.74% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.17 , Outputs: tensor([0.0991])


 | Global Training Round : 77 |

user 68, loss 2.2941757225990296, acc 0.08
user 35, loss 2.2986105537414554, acc 0.12
user 80, loss 2.2995680022239684, acc 0.06
user 71, loss 2.2993898659944536, acc 0.1
user 64, loss 2.3008801865577695, acc 0.06
user 25, loss 2.297919760942459, acc 0.04
user 73, loss 2.2971837782859805, acc 0.1
user 62, loss 2.295150020718575, acc 0.02
user 77, loss 2.2964150404930113, acc 0.18
user 20, loss 2.299492188692093, acc 0.04
 
Avg Training Stats after 77 global rounds:
Training Loss : 2.2975721306727306
Global model Benign Test Accuracy: 11.80% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 232.34 , Outputs: tensor([0.0979])


 | Global Training Round : 78 |

user 24, loss 2.295868788361549, acc 0.1
user 93, loss 2.2969267028570175, acc 0.16
user 42, loss 2.296049281358719, acc 0.14
user 81, loss 2.2971072578430176, acc 0.16
user 4, loss 2.300682363510132, acc 0.12
user 98, loss 2.2930545383691787, acc 0.12
user 72, loss 2.299660158157349, acc 0.1
user 49, loss 2.295430991053581, acc 0.06
user 86, loss 2.299723923802376, acc 0.06
user 23, loss 2.2967290091514587, acc 0.1
 
Avg Training Stats after 78 global rounds:
Training Loss : 2.2975663764518806
Global model Benign Test Accuracy: 14.18% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.63 , Outputs: tensor([0.0996])


 | Global Training Round : 79 |

user 39, loss 2.2969109737873077, acc 0.1
user 51, loss 2.300967313051223, acc 0.1
user 95, loss 2.300435224175453, acc 0.24
user 44, loss 2.295630604028702, acc 0.08
user 23, loss 2.295498154759407, acc 0.1
user 82, loss 2.2964364552497867, acc 0.1
user 94, loss 2.2997380906343463, acc 0.06
user 42, loss 2.294433749914169, acc 0.14
user 8, loss 2.2988606870174406, acc 0.16
user 33, loss 2.2971581357717517, acc 0.12
 
Avg Training Stats after 79 global rounds:
Training Loss : 2.297566889899818
Global model Benign Test Accuracy: 11.18% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.81 , Outputs: tensor([0.0985])


 | Global Training Round : 80 |

user 82, loss 2.2955005115270617, acc 0.1
user 73, loss 2.2969140666723247, acc 0.1
user 8, loss 2.2981122851371762, acc 0.16
user 87, loss 2.3022576534748076, acc 0.08
user 99, loss 2.301382511854172, acc 0.08
user 89, loss 2.2956853049993513, acc 0.08
user 5, loss 2.2941139101982118, acc 0.06
user 51, loss 2.3009308815002436, acc 0.1
user 34, loss 2.295289816260338, acc 0.12
user 93, loss 2.295686011314392, acc 0.16
 
Avg Training Stats after 80 global rounds:
Training Loss : 2.2975671449672435
Global model Benign Test Accuracy: 11.19% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 233.12 , Outputs: tensor([0.0972])


 | Global Training Round : 81 |

user 24, loss 2.2953692615032195, acc 0.1
user 29, loss 2.294363084435463, acc 0.2
user 19, loss 2.2978561723232263, acc 0.06
user 27, loss 2.295498292446136, acc 0.08
user 95, loss 2.300331060886383, acc 0.24
user 3, loss 2.293975051045418, acc 0.14
user 1, loss 2.303116185069084, acc 0.14
user 18, loss 2.295106611847878, acc 0.08
user 35, loss 2.2977794176340103, acc 0.12
user 96, loss 2.298118317723274, acc 0.12
 
Avg Training Stats after 81 global rounds:
Training Loss : 2.297562011640381
Global model Benign Test Accuracy: 12.58% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.33 , Outputs: tensor([0.0989])


 | Global Training Round : 82 |

user 83, loss 2.2993543124198914, acc 0.12
user 77, loss 2.2975459533929823, acc 0.18
user 65, loss 2.299890096783638, acc 0.08
user 48, loss 2.297802338004112, acc 0.06
user 70, loss 2.298668259382248, acc 0.04
user 72, loss 2.2980362725257875, acc 0.1
user 1, loss 2.302680506706238, acc 0.14
user 97, loss 2.3004453945159913, acc 0.14
user 95, loss 2.3003700160980225, acc 0.24
user 11, loss 2.3030738765001297, acc 0.12
 
Avg Training Stats after 82 global rounds:
Training Loss : 2.2975891420183387
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.56 , Outputs: tensor([0.1038])


 | Global Training Round : 83 |

user 99, loss 2.3001095551252364, acc 0.08
user 75, loss 2.3008370625972745, acc 0.1
user 92, loss 2.300391429662705, acc 0.08
user 51, loss 2.3003989177942277, acc 0.1
user 68, loss 2.2965401500463485, acc 0.14
user 36, loss 2.295263112783432, acc 0.16
user 49, loss 2.2956805485486984, acc 0.06
user 1, loss 2.3025432407855986, acc 0.14
user 3, loss 2.294560052752495, acc 0.14
user 57, loss 2.2982931154966355, acc 0.06
 
Avg Training Stats after 83 global rounds:
Training Loss : 2.297599654988711
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 100.00%, Malicious Loss: 226.61 , Outputs: tensor([0.1037])


 | Global Training Round : 84 |

user 34, loss 2.296207941174507, acc 0.12
user 94, loss 2.2999214220047, acc 0.06
user 71, loss 2.300523516535759, acc 0.1 84%|████████▍ | 84/100 [40:05<07:41, 28.87s/it] 85%|████████▌ | 85/100 [40:34<07:13, 28.88s/it] 86%|████████▌ | 86/100 [41:03<06:44, 28.89s/it] 87%|████████▋ | 87/100 [41:32<06:15, 28.91s/it] 88%|████████▊ | 88/100 [42:01<05:46, 28.92s/it] 89%|████████▉ | 89/100 [42:27<05:09, 28.12s/it] 90%|█████████ | 90/100 [42:56<04:44, 28.40s/it] 91%|█████████ | 91/100 [43:25<04:17, 28.60s/it] 92%|█████████▏| 92/100 [43:54<03:49, 28.73s/it] 93%|█████████▎| 93/100 [44:23<03:21, 28.82s/it] 94%|█████████▍| 94/100 [44:52<02:53, 28.88s/it] 95%|█████████▌| 95/100 [45:21<02:24, 28.93s/it]
user 99, loss 2.3001728957891463, acc 0.08
user 21, loss 2.3021879887580874, acc 0.06
user 83, loss 2.298288649916649, acc 0.12
user 20, loss 2.3004625111818315, acc 0.04
user 48, loss 2.2975788491964337, acc 0.06
user 84, loss 2.301546388268471, acc 0.04
user 30, loss 2.2988683116436, acc 0.14
 
Avg Training Stats after 84 global rounds:
Training Loss : 2.297623181089404
Global model Benign Test Accuracy: 13.03% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.79 , Outputs: tensor([0.1015])


 | Global Training Round : 85 |

user 71, loss 2.300219770669937, acc 0.1
user 23, loss 2.2962676018476484, acc 0.1
user 58, loss 2.29890313744545, acc 0.08
user 76, loss 2.2951834237575537, acc 0.18
user 0, loss 2.2980169856548307, acc 0.12
user 8, loss 2.2992923033237456, acc 0.16
user 89, loss 2.295924617052078, acc 0.12
user 95, loss 2.3003198289871216, acc 0.24
user 21, loss 2.302312536239624, acc 0.06
user 45, loss 2.3004637849330902, acc 0.1
 
Avg Training Stats after 85 global rounds:
Training Loss : 2.2976357365941302
Global model Benign Test Accuracy: 12.59% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.84 , Outputs: tensor([0.0994])


 | Global Training Round : 86 |

user 44, loss 2.2958522778749466, acc 0.08
user 58, loss 2.2988525635004042, acc 0.08
user 77, loss 2.2977166360616685, acc 0.18
user 73, loss 2.2975402051210407, acc 0.1
user 74, loss 2.2956829005479813, acc 0.1
user 96, loss 2.2978476190567014, acc 0.12
user 48, loss 2.2975908488035204, acc 0.06
user 80, loss 2.300283227562905, acc 0.06
user 22, loss 2.2973126906156542, acc 0.16
user 35, loss 2.2978767943382263, acc 0.12
 
Avg Training Stats after 86 global rounds:
Training Loss : 2.2976359672889464
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.96 , Outputs: tensor([0.0993])


 | Global Training Round : 87 |

user 31, loss 2.3009389120340344, acc 0.1
user 49, loss 2.2951323252916334, acc 0.06
user 22, loss 2.2960962015390396, acc 0.16
user 6, loss 2.301227232813835, acc 0.1
user 28, loss 2.295957830548286, acc 0.1
user 99, loss 2.300877778530121, acc 0.08
user 77, loss 2.295730967521668, acc 0.18
user 85, loss 2.299734862446785, acc 0.14
user 92, loss 2.301176234483719, acc 0.08
user 9, loss 2.294937533736229, acc 0.14
 
Avg Training Stats after 87 global rounds:
Training Loss : 2.2976422318936085
Global model Benign Test Accuracy: 13.63% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.57 , Outputs: tensor([0.1017])


 | Global Training Round : 88 |

user 49, loss 2.2938926166296008, acc 0.06
user 66, loss 2.2931883227825165, acc 0.06
user 71, loss 2.2996779161691663, acc 0.1
user 23, loss 2.2976770663261408, acc 0.1
user 84, loss 2.3014123630523677, acc 0.1
user 92, loss 2.2996500301361085, acc 0.08
user 44, loss 2.2939989042282107, acc 0.08
user 42, loss 2.2961078333854674, acc 0.14
user 69, loss 2.2938354486227035, acc 0.06
user 12, loss 2.298677969574928, acc 0.16
 
Avg Training Stats after 88 global rounds:
Training Loss : 2.2976327957026665
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.90 , Outputs: tensor([0.1014])


 | Global Training Round : 89 |

Malcious user 7 is selected!
user 7, loss 2.223233127593994, acc 0.12, mal loss 2.130103826522827, mal acc 1.0
user 53, loss 2.2989507234096527, acc 0.1
user 30, loss 2.298711451292038, acc 0.14
user 86, loss 2.2991595190763476, acc 0.06
user 9, loss 2.2927217209339146, acc 0.14
user 48, loss 2.299467284083366, acc 0.06
user 50, loss 2.3023661994934086, acc 0.16
user 84, loss 2.3015018957853317, acc 0.1
user 45, loss 2.30124142229557, acc 0.1
user 71, loss 2.299339004158974, acc 0.1
 
Avg Training Stats after 89 global rounds:
Training Loss : 2.297565789400527
Global model Benign Test Accuracy: 9.89% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 229.44 , Outputs: tensor([0.1008])


 | Global Training Round : 90 |

user 45, loss 2.300596311688423, acc 0.1
user 65, loss 2.3001037871837617, acc 0.08
user 4, loss 2.2999547260999678, acc 0.12
user 17, loss 2.3002436959743497, acc 0.06
user 31, loss 2.300268234610558, acc 0.1
user 28, loss 2.295650241971016, acc 0.1
user 60, loss 2.2950704181194306, acc 0.06
user 46, loss 2.2996398884058005, acc 0.06
user 88, loss 2.2987370121479036, acc 0.2
user 79, loss 2.2983838647603987, acc 0.1
 
Avg Training Stats after 90 global rounds:
Training Loss : 2.2975802230527003
Global model Benign Test Accuracy: 9.32% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.47 , Outputs: tensor([0.1018])


 | Global Training Round : 91 |

user 51, loss 2.3003567004203793, acc 0.1
user 69, loss 2.292671154141426, acc 0.06
user 58, loss 2.2990527677536012, acc 0.08
user 21, loss 2.302505888938904, acc 0.06
user 16, loss 2.3006847411394125, acc 0.14
user 67, loss 2.2980890554189677, acc 0.02
user 65, loss 2.300370187759399, acc 0.1
user 88, loss 2.298130927681923, acc 0.2
user 38, loss 2.301447640657425, acc 0.08
user 19, loss 2.2979653024673463, acc 0.06
 
Avg Training Stats after 91 global rounds:
Training Loss : 2.2975972253997905
Global model Benign Test Accuracy: 12.56% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.11 , Outputs: tensor([0.1022])


 | Global Training Round : 92 |

user 34, loss 2.2977264225482945, acc 0.12
user 74, loss 2.2969657707214353, acc 0.1
user 65, loss 2.3004275649786, acc 0.1
user 29, loss 2.2942751443386085, acc 0.1
user 55, loss 2.298417512774468, acc 0.08
user 52, loss 2.2984014260768886, acc 0.14
user 16, loss 2.299787144064903, acc 0.14
user 38, loss 2.301997970938683, acc 0.08
user 41, loss 2.3010826575756074, acc 0.02
user 22, loss 2.2969748860597607, acc 0.1
 
Avg Training Stats after 92 global rounds:
Training Loss : 2.297608186536833
Global model Benign Test Accuracy: 9.32% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.95 , Outputs: tensor([0.0983])


 | Global Training Round : 93 |

user 41, loss 2.300414096713066, acc 0.02
user 9, loss 2.2956583255529406, acc 0.14
user 14, loss 2.3004134899377826, acc 0.12
user 59, loss 2.2963552409410477, acc 0.14
user 63, loss 2.296374862790107, acc 0.16
user 33, loss 2.297865424156189, acc 0.12
user 94, loss 2.299810159802437, acc 0.06
user 46, loss 2.3002219825983046, acc 0.14
user 76, loss 2.2943846368789673, acc 0.18
user 72, loss 2.2988816690444946, acc 0.12
 
Avg Training Stats after 93 global rounds:
Training Loss : 2.297612808066991
Global model Benign Test Accuracy: 10.10% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 235.49 , Outputs: tensor([0.0949])


 | Global Training Round : 94 |

user 24, loss 2.2963427281379696, acc 0.1
user 67, loss 2.297618552446365, acc 0.16
user 47, loss 2.3004083859920508, acc 0.12
user 72, loss 2.2987895441055293, acc 0.1
user 19, loss 2.297247880101204, acc 0.06
user 54, loss 2.299820465445518, acc 0.1
user 56, loss 2.2977117061614987, acc 0.06
user 51, loss 2.300395929813385, acc 0.1
user 74, loss 2.296784175634384, acc 0.1
user 36, loss 2.2947982847690582, acc 0.16
 
Avg Training Stats after 94 global rounds:
Training Loss : 2.2976168395264986
Global model Benign Test Accuracy: 9.60% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 233.23 , Outputs: tensor([0.0971])


 | Global Training Round : 95 |

user 5, loss 2.2941640055179597, acc 0.06
user 56, loss 2.2975832933187483, acc 0.06
user 98, loss 2.2935783237218854, acc 0.12
user 2, loss 2.29806824862957, acc 0.1
user 65, loss 2.3010250741243365, acc 0.08
user 29, loss 2.29447134912014, acc 0.2
user 95, loss 2.3002290070056914, acc 0.24
user 9, loss 2.2954612296819685, acc 0.14
user 46, loss 2.2994949430227285, acc 0.14
user 36, loss 2.293637993335724, acc 0.16
 
Avg Training Stats after 95 global rounds:
Training Loss : 2.2976079396025133
Global model Benign Test Accuracy: 9.65% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.73 , Outputs: tensor([0.0995])


 | Global Training Round : 96 |

user 11, loss 2.3029511809349055, acc 0.1
user 60, loss 2.2947888463735575, acc 0.06
user 30, loss 2.2977509921789165, acc 0.14
user 72, loss 2.297892630696297, acc 0.1
user 90, loss 2.2987818163633347, acc 0.08 96%|█████████▌| 96/100 [45:50<01:55, 28.93s/it] 97%|█████████▋| 97/100 [46:19<01:26, 28.91s/it] 98%|█████████▊| 98/100 [46:48<00:57, 28.89s/it] 99%|█████████▉| 99/100 [47:17<00:28, 28.88s/it]100%|██████████| 100/100 [47:45<00:00, 28.88s/it]100%|██████████| 100/100 [47:45<00:00, 28.66s/it]

user 43, loss 2.2985160058736804, acc 0.08
user 22, loss 2.2979081040620803, acc 0.16
user 34, loss 2.2964088106155396, acc 0.12
user 83, loss 2.2994064766168596, acc 0.12
user 27, loss 2.2951027435064315, acc 0.08
 
Avg Training Stats after 96 global rounds:
Training Loss : 2.297611510655843
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 228.56 , Outputs: tensor([0.1017])


 | Global Training Round : 97 |

user 27, loss 2.2937760084867476, acc 0.08
user 54, loss 2.3006326377391817, acc 0.1
user 38, loss 2.3015630662441255, acc 0.08
user 50, loss 2.3015956676006324, acc 0.16
user 66, loss 2.293568237423897, acc 0.06
user 91, loss 2.299082200527191, acc 0.08
user 16, loss 2.300550090670585, acc 0.14
user 30, loss 2.2984174901247028, acc 0.14
user 2, loss 2.296818894743919, acc 0.1
user 68, loss 2.2958096879720684, acc 0.14
 
Avg Training Stats after 97 global rounds:
Training Loss : 2.2976173857846827
Global model Benign Test Accuracy: 9.81% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 230.78 , Outputs: tensor([0.0995])


 | Global Training Round : 98 |

user 37, loss 2.3007431685924526, acc 0.06
user 48, loss 2.298931196928024, acc 0.06
user 90, loss 2.29771069586277, acc 0.08
user 74, loss 2.2972301757335662, acc 0.1
user 88, loss 2.2985598069429396, acc 0.2
user 68, loss 2.2947073853015896, acc 0.14
user 54, loss 2.3000209504365925, acc 0.1
user 6, loss 2.3011605715751644, acc 0.1
user 22, loss 2.295615444779396, acc 0.1
user 71, loss 2.299688113331795, acc 0.1
 
Avg Training Stats after 98 global rounds:
Training Loss : 2.2976257466537007
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.63 , Outputs: tensor([0.0986])


 | Global Training Round : 99 |

user 43, loss 2.297411679029465, acc 0.08
user 2, loss 2.2982176482677454, acc 0.1
user 68, loss 2.293878693580628, acc 0.14
user 50, loss 2.3019013023376464, acc 0.16
user 61, loss 2.3012108814716337, acc 0.08
user 9, loss 2.292856943011284, acc 0.14
user 18, loss 2.2956064242124556, acc 0.08
user 56, loss 2.2970883727073668, acc 0.06
user 75, loss 2.301530296206474, acc 0.1
user 81, loss 2.2972706693410876, acc 0.16
 
Avg Training Stats after 99 global rounds:
Training Loss : 2.2976264693240327
Global model Benign Test Accuracy: 10.00% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 232.58 , Outputs: tensor([0.0977])


 | Global Training Round : 100 |

user 75, loss 2.300965015888214, acc 0.1
user 29, loss 2.2956419456005097, acc 0.1
user 9, loss 2.2929008579254146, acc 0.14
user 72, loss 2.300180752277374, acc 0.1
user 18, loss 2.294128466844559, acc 0.08
user 92, loss 2.2996751612424853, acc 0.08
user 6, loss 2.3008876800537115, acc 0.1
user 73, loss 2.2972813320159915, acc 0.1
user 77, loss 2.2943654644489286, acc 0.18
user 49, loss 2.2955188339948656, acc 0.06
 
Avg Training Stats after 100 global rounds:
Training Loss : 2.2976217501410843
Global model Benign Test Accuracy: 9.91% 

Global model Malicious Accuracy: 0.00%, Malicious Loss: 231.29 , Outputs: tensor([0.0990])

 
 Results after 100 global rounds of training:
Traceback (most recent call last):
  File "fedavg.py", line 214, in <module>
    print("|---- Avg Train Accuracy: {:.2f}%".format(100*train_accuracy[-1]))
IndexError: list index out of range
